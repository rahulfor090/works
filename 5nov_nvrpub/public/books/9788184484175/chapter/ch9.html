<div class="chapter"><div class="chapter"><h2 class="title">CHAPTER 9. <a name="page117"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">117</span></span>Laboratory Research</h2><p class="aligncenter"><span class="italic">“The science of life” is a superb and dazzlingly lighted hall which may be reached only by passing through a long and ghastly kitchen.</span></p><p class="alignright"><span class="italic">— CLAUDE BERNARD</span></p><p class="noindent">Laboratory is the long and ghastly kitchen through which biological research material must pass before the secrets of life reveal themselves to us. Unlike the vast variability that characterizes the human beings or animals who are the source of the biological material, the test tubes and Petri dishes, the reagents and refrigerators of the laboratory present a picture of uniformity and precision. The conditions under which laboratory work is done are well defined: the temperature and duration of incubation, the concentration and volume of a reagent to be added, the rate of rotation of the centrifuge, etc. are stated in minute detail and executed with meticulous precision (<a href="#ch9fig1" class="ulink-inter">Fig. 9.1</a>). Therefore we have great confidence in lab results, specially if they are in the form of a computer printout or digital display of automated equipment. If there is any waywardness in data, we look for its causes in the biological material rather than in the laboratory rituals to which it was subjected. However, it has been realized that the human beings who work in the lab, the equipment, the reagents, the method selected for measurement, and the calculations involved in generation of data, can all be major sources of error. Therefore attention to all these factors is important for the lab results to be reliable. Some of these issues will be addressed briefly in this chapter.</p><div class="section" id="ch9lev1sec1"><h1 class="title">PERSONNEL</h1>
<p class="noindent">The persons employed in the lab should be adequately qualified and trained, and above all should have a strong commitment to duty. The number of persons working in the lab should be just right in relation to the workload.<a name="page118"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">118</span></span></p>
<div class="figure" id="ch9fig1" data-label="Fig. 9.1"><div class="title"><span class="item-label">Fig. 9.1</span> Laboratory research is done under conditions which are defined with meticulous precision! <span class="italic">(Concept and Execution: R Gopalakrishnan, AIIMS)</span></div><img alt="Fig. 9.1" src="/MediumImage/118-1.jpg"><div class="additional-markup"></div></div>
<p class="noindent"><a name="page119"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">119</span></span>If the workload is too heavy, the quality of the work suffers. If the number of persons is far too many for the work, the quality is not necessarily better; in fact, the quality may suffer because the gossip mill becomes more active. Whether it is better to have temporary staff or permanent employees, there is something to be said for both. In general, it is probably desirable to have in the lab one senior, competent and committed technologist who is a permanent employee. The rest of the staff should be temporary ‘scheme staff’, each of whom should stay for at least 2 years, and preferably 5-10 years. If the turnover is very rapid, there is no time for proper training, and any time spent on their training is wasted. On the other hand, if a person does not get a permanent job even after 10 years, he is frustrated, which is bad for the person as well as the quality of the work. Therefore, the principal investigator should ideally manage the projects in such a way that there is a balance between continuity and renewal of staff and there is enough time for adequate training and competency evaluation of new staff. The dedication and integrity of the lab staff are more important determinants of the quality of lab work than any of the other factors discussed below. Therefore all efforts should be made to get good people, and provide them an environment in which they stay good.</p>
</div><div class="section" id="ch9lev1sec2"><h1 class="title">FACILITIES</h1>
<p class="noindent">Among the facilities, the major determinants of the quality of the data generated by a lab are space and instrumentation.</p>
<div class="section" id="ch9lev2sec1"><h2 class="title">Space</h2>
<p class="noindent">Gamgee's remarks (<a href="/9788184484175/chapter/ch2#ch2fig2" class="ulink-exter">Fig. 2.2</a>) about the quality of a bird's song not being determined by its cage notwithstanding, adequate and well-organised space does matter (Howerton et at 2005). The space should be adequate for the instruments, reagents, necessary documents, and for the staff to work comfortably without getting into one-another's way. The arrangement of material should be such as to maximize convenience, comfort and efficiency. The temperature and humidity should be appropriate for the type of tests to be done. The lighting should be adequate for efficient work: a bright room is itself a mood-elevator! The surfaces should also receive some attention: the floor should not be slippery, the balance should be placed on a vibration-free surface, and if spillage of corrosive material or stains is likely, the surface of the bench should be suitable for such exigencies.<a name="page120"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">120</span></span></p>
</div>
<div class="section" id="ch9lev2sec2"><h2 class="title">Instrumentation</h2>
<p class="noindent">Proper installation, care and calibration of instruments is important. A log book in which the time and duration of use, and the name of the user are recorded, should be placed with every instrument. Any difficulty or error observed during use of the instrument should also be recorded in the log book. The instruction manual and the contact information of the manufacturer, dealer and the agency responsible for maintenance of the instrument should be kept safe and handy. Although instruments are not living beings, they seem to respond to love. If handled with care and concern, they last longer and work better.</p>
<p class="indent">The glassware should be cleaned thoroughly and properly, and rinsed appropriately with deionized water. The distilled and deionized water used in the lab should be checked periodically for its quality, because the quality of the water can affect the accuracy of many assays. The accuracy of micropipettes and thermometers should be verified.</p>
<div class="section" id="ch9lev3sec1"><h3 class="title">Automation</h3>
<p class="noindent">There is a steady trend towards automation in instruments. Complete automation implies that the sample is introduced at one end, the result displayed or printed out at the other end. All the steps involved in the test are performed in the right sequence automatically by the instrument. The technician has to only replenish the reagents periodically and do some routine maintenance work for the instrument. Automation saves time and avoids tedious mechanical repetition of the procedure again and again. Both these factors are particularly important if a large number of samples have to be handled on the same day. Automation can also increase the accuracy of tests by introducing greater accuracy in pipetting, time of incubation, etc., and by avoiding ‘human errors’. But automation does not necessarily and automatically increase accuracy. The instrument has to be used properly to get accurate results. One source of error is the contamination of a sample by the preceding sample. This naturally leads to a proportionate contribution to the results by the preceding sample. The effect, called the carry over effect can be avoided by using a wash liquid or backflushing of the probe. In some instruments, the carry over effect is avoided by injecting an air bubble between two consecutive samples.<a name="page121"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">121</span></span></p>
</div>
</div>
</div><div class="section" id="ch9lev1sec3"><h1 class="title">PRELIMINARY PREPARATION</h1>
<p class="noindent">Before beginning a test, assay or procedure in the lab and using it to generate research data, adequate preparation is necessary. First, if several alternative methods are available, the method to be used in the lab has to be chosen. The choice would be based on the accuracy, feasibility and cost-effectiveness of the method. Next, if all the equipment required is not available, it should be procured, fabricated, improvised, borrowed, or its availability with a neighbouring lab ensured. If necessary, a choice should also be made between preparing reagents in the lab or procuring a kit. These materials should be ordered, and on receipt stored as directed by the manufacturer. One should not forget to order also the control and calibration materials. In order to familiarize and train the staff and to standardize the method, several trial runs should be conducted in an organized manner so that the precision and accuracy of the method (see Quality Control below) in the hands of the lab staff can be determined and improved upon. When the researchers are satisfied that the method is working, a Standard Operations Procedure (SOP) Manual should be prepared in which all the details should be written down. The method, as available in a publication, or in reagent inserts, is not a substitute for the SOP. These sources of information are important, and may be included in the SOP, but the SOP for each lab is unique, and incorporates also the tips acquired through experience. As the experience grows, the SOP may be revised. But old SOPs should also be preserved. A complete history of SOPs can also turn out to have academic value or practical utility some time in the future.</p>
</div><div class="section" id="ch9lev1sec4"><h1 class="title">SAMPLE COLLECTION</h1>
<p class="noindent">The subject should be in the ‘right state’ at the time of sample collection. For some tests, the patient should be fasting: in such cases it may be important also to ensure that the gap between the last meal on the previous day and sample collection should be 12-14 hours. It may also be necessary to collect the sample at the same time of the day every time, for each subject (as for glucocorticoid estimation). The diet taken on the days preceding the test may have some significance (as for glucose tolerance test). Smoking, ‘just a cup of tea without sugar’, exertion or anxiety may also affect the results. Even the posture of the subject at the time of sample collection may have some significance (Tolonen et al 2005). Once the sample has been collected, a fool-proof system for labeling the specimens should be <a name="page122"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">122</span></span>established to avoid mix-ups. Further, handling of samples and the conditions under which the samples are stored should also receive attention.</p>
<p class="indent">The above aspects affect the accuracy of results. In addition, precautions are also necessary to ensure safety of the subjects and lab personnel. Universal precautions are necessary when dealing with blood or some other fluids (e.g. semen). These fluids are to be always treated as if infected with HIV, and hepatitis B and hepatitis C viruses. Sterile, disposable, single-use syringes and needles, gloves, gowns and protective eyewear for the personnel, and safe disposal of used syringes, needles and gloves is important (Howerton et at 2005). If the reader is involved in research which needs such precautions, s/he is urged to read the universal precautions in detail and observe them in the lab.</p>
</div><div class="section" id="ch9lev1sec5"><h1 class="title">THE TEST: QUALITY ASSURANCE</h1>
<p class="noindent">Adequate training, proper sample collection, and following the SOP meticulously improve the chances of correct results, but do not guarantee them. Further, it is not enough that the results are right; one should also know that they are right, and it should be possible to demonstrate to others that they are right. This can be done by having a quality control programme in place. Quality control includes all the methods which enable us to detect and correct errors and thereby ensure consistently precise and accurate data. It includes procedures which help decide on a day-to-day basis whether ‘today's results’ are reliable. Quality control also includes long-term monitoring to ensure consistency in spite of changes in the quality control pool, batches of reagents, performance of equipment, or the personnel doing the analysis (Kaplan and Pesce 1989, Howerton et al 2005).</p>
<p class="indent">Before going further, it may be useful at this stage to clarify a few terms. <span class="italic">Precision</span> refers to variation in results if the test is repeated several times on the same sample. Less the variability, greater is the precision. However, precision does not guarantee accuracy. The readings may be repeatedly very similar, but they may be all equally inaccurate! <span class="italic">Accuracy</span> refers to how close the measured value is to the true value. Accuracy may not be always associated with high precision. The average of repeated readings may be vary accurate, but if the scatter is wide, the level of precision is low (<a href="#ch9fig2" class="ulink-inter">Fig. 9.2</a>). <span class="italic">Sensitivity</span> of a method refers to the accuracy with which it can detect small differences in concentration of the analyte.<a name="page123"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">123</span></span></p>
<div class="figure" id="ch9fig2" data-label="Fig. 9.2"><div class="title"><span class="item-label">Fig. 9.2</span> Four different situations discovered by repeating a test five times each. A. Precise but not accurate. B. Accurate and precise. C. Accurate but not precise. D. Neither accurate nor precise. In practice, five repetitions are too few to draw such conclusions: about twenty repetitions would be required for the purpose</div><img alt="Fig. 9.2" src="/MediumImage/123-1.jpg"><div class="additional-markup"></div></div>
<p class="noindent">(Analyte is the substance being analysed or measured). <span class="italic">Sensitivity</span> and accuracy usually go hand in hand. Specificity of a method refers to the extent to which substances other than the analyte are able to influence the results. For example, if in a radioimmunoassay for LH, the antibody binds to some extent also with FSH, the concentration of FSH in the sample will also influence the results. Or, in a colorimetric method, if hemoglobin increases the intensity of the color of the reaction mixture, hemolysed samples will give higher readings. If the degree of contamination by the interfering substance is constant, a method lacking specificity may be very precise but inaccurate.</p>
<p class="indent">Errors in accuracy are of two types. <span class="italic">Random errors</span> fluctuate unpredictably on either side of the true value. Random errors can be detected and quantified by replication experiments. If 10 ‘copies’ of the same sample are analysed in an assay, we can estimate the intra-assay variation. If the same sample is analysed 10 times in 10 different batches of the assay, we can estimate the inter-assay variation. Intra-assay variation is generally less than inter-assay variation. Ideally, the coefficient of variation (SD/Mean × 100) for either should be less than 10%. Interestingly, replication experiments not only quantify random error, they also help in reducing it. <span class="italic">Systematic error</span> is always in the same direction and has a predictable pattern. Systematic errors are of two types. <span class="italic">Constant systematic error</span> has a fixed magnitude irrespective of the concentration of the analyte. For example, a method for blood glucose having a constant systematic error might give an <a name="page124"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">124</span></span>error of +20 mg/dL for all samples. For samples having true blood glucose levels of 100, 180 and 340 mg/dL, this method would give values of 120, 200 and 360 mg/dL respectively. <span class="italic">Proportional systematic error</span> has a magnitude that is a constant fraction of the concentration of the analyte. For example, a method for blood glucose having a proportional systematic error might give an error of +10% for all samples. For samples having true blood glucose levels of 100, 180 and 340 mg/dL, this method would give values of 110, 198 and 374 mg/dL respectively.</p>
<p class="indent">Constant systematic error (CSE) is generally due to an interfering substance, e.g. hemoglobin or bilirubin. To determine CSE, the samples are ‘spiked’ with the interfering substance. For example, the same blood sample might be analysed without hemolysis and after hemolysis (deliberate) to determine if hemoglobin is the culprit, and how much error it leads to. Or, a non-icteric blood sample might be analysed as such and also after being spiked with bilirubin. The difference in results would give the magnitude of the CSE.</p>
<p class="indent">Proportional systematic error (PSE) is generally due to erroneous calibration. PSE is determined by recovery experiments. Varying amounts of the analyte are added to the same sample and all the resulting specimens analysed. The additional concentration detected in each specimen gives the amount ‘recovered’. Recovery is calculated as the percentage of the amount added. The percentage is constant if there is a PSE.</p>
<div class="section" id="ch9lev2sec3"><h2 class="title">Quality Control Pool</h2>
<p class="noindent">Quality control pool consists of pooled patient specimens or a commercially available pool material which can be included in duplicate with every run of analysis, or for every 20 samples. The first time the pool is analysed, it is assumed that the method is accurate. While setting up the method, the quality control pool material is analyzed in duplicate from each of the two separate vials for 10 days. The average of the 40 values so obtained gives the temporary target average (TTA), and TTA ± 2 SD gives the range of the acceptable control limit. The process of including the quality control pool material everyday along with the samples continues. The final target average (FTA) is determined from the average of the values generated over a 2-month period. The Usual SD (USD) is calculated from the average of 6-monthly SDs. The final control limits are FTA ± 2USD. As far as possible, the same quality control material should be used for about one year. When a change has to be made, the old and new control <a name="page125"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">125</span></span>material should be run simultaneously, the FTA of the old material providing a reference point for fixing the FTA of the new material. In cases where specimens might have a wide range of values, it is preferable to have three quality control pools containing high, medium and low concentrations of the analyte.</p>
<p class="indent">If repeated analysis of the quality control material gives values within the control limit, we can be sure of the reproducibility (or precision) of the results. In order to determine and monitor the accuracy of the method, we need calibration material.</p>
</div>
<div class="section" id="ch9lev2sec4"><h2 class="title">Calibration Material</h2>
<p class="noindent">Calibration material has a known concentration of the analyte as determined by the manufacturer of reagents (or the user). The value assigned to the concentration in the calibration material is based on assay by the reference method (which may be too expensive or cumbersome for routine use). Running the calibration material in an assay helps in assigning reliably accurate values to the quality control material as well as test specimens. There are limitations on the total amount of calibration material that may be bought at a time, and also the shelf life of the material. Therefore, the batch of the calibration material would inevitably change from time to time. As in case of quality control material, there should be a period of overlap when the old as well as new calibration material are both used. Ideally the overlap period should be 6 weeks. Any systematic difference between the values obtained with the old and the new calibrators may be detected by comparing the values of the quality control material with the two calibrators. The calibrator which consistently gives values close to the FTA may be taken as the ‘correct’ calibrator for the purposes of the lab.</p>
</div>
<div class="section" id="ch9lev2sec5"><h2 class="title">Change of Reagents</h2>
<p class="noindent">Any change, whether it is change of reagents, equipment or personnel may influence the results. After every change, some old samples should be run again along with the quality control and calibration material. Such checks can help avoid systematic errors and improve precision. Random errors could still escape undetected unless the assays of significantly abnormal values are repeated.</p>
</div>
<div class="section" id="ch9lev2sec6"><h2 class="title">Daily Decisions</h2>
<p class="noindent">Detecting errors is not enough: they need action. Apart from repeating the assays, recurrent errors call for checking the reagents, quality control pool, calibrator, equipment, samples (presence of hemolysed <a name="page126"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">126</span></span>blood, clots, etc.), and the performance of the personnel. All quality control data and action taken should be documented. A monthly plot of readings obtained on the quality control pool is called the Levy-Jennings plot.</p>
</div>
<div class="section" id="ch9lev2sec7"><h2 class="title">Levy-Jennings Plot</h2>
<p class="noindent">The visual impression of a month-long daily plot of quality control pool values can be very revealing (<a href="#ch9fig3" class="ulink-inter">Fig. 9.3</a>). For example it might show unacceptable random errors, or an abrupt shift to higher or lower values, or a progressive trend towards higher or lower values. Classification of the defect in quality can provide a clue to the likely cause of the problem. For example, increase in random errors might point to carelessness on the part of lab staff, an abrupt shift is likely to be due to a change in the calibrator, and a progressive trend might be due to a developing drift in equipment.</p>
<p class="indent">Besides the Levy-Jennings plot, there are detailed algorithms available for interpreting monthly data and deciding on the action to be taken. In addition to the monthly review, there is also a need for long term review, which may eventually lead to improvements in methodology, or adoption of a new method.</p>
<div class="figure" id="ch9fig3" data-label="Fig. 9.3"><div class="title"><span class="item-label">Fig. 9.3</span> Levy-Jennings plot. The plot shows the daily average of the value of the quality control pool over a one-month period. The acceptable limits of mean ± 2SD have been shown by dotted lines. On days 1-6, the assays are satisfactory; on days 7-13, random errors have increased in magnitude (low precision); on days 14-22, a systematic error has suddenly shifted the value upwards (high precision but low accuracy); days 23-31, there is a progressive trend towards lower values</div><img alt="Fig. 9.3" src="/MediumImage/126-1.jpg"><div class="additional-markup"></div></div>
<a name="page127"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">127</span></span>
</div>
<div class="section" id="ch9lev2sec8"><h2 class="title">External Control</h2>
<p class="noindent">There are some authoritative impartial agencies (e.g. American Association of Bioanalysis) who have arrangements for analysis of unknown samples sent by participating laboratories. Comparing the results obtained by the external agency with its own results for the same samples is a good way to maintain standards as well as inspire confidence in the lab. External control also helps in accuracy control because internal control is primarily geared towards control of precision.</p>
</div>
<div class="section" id="ch9lev2sec9"><h2 class="title">Accuracy Control</h2>
<p class="noindent">Precision control precedes accuracy control because unless the inherent variability of the method is known, and has been reduced to the lowest level possible, accuracy cannot be achieved. Having achieved good precision, if external control repeatedly indicates significant errors in accuracy, it is time to direct attention to accuracy. Accuracy may be investigated in two ways. The easier way is to analyse samples with a known concentration of the analyte (e.g. calibration material) and determine the intra-assay and inter-assay variation. Another way, which may not be always feasible for a lab is to analyse the same set of samples simultaneously by the currently used method as well as by a reference method. If the current method has error, it should be determined whether the error is random or systematic; and if it is systematic, whether it is constant or proportional. If the error cannot be eliminated, a new method known to be better than the current method should be adopted. The new method will also need evaluation and quality control in the same way as the current method. Quality needs eternal vigilance, and improvement is indeed a never-ending quest.</p>
</div>
</div><div class="section" id="ch9lev1sec6"><h1 class="title">AFTER THE TEST</h1>
<p class="noindent">A good lab information system should be established for accurate recording, storage, archiving and retrieval of results. A computer-based system is desirable because the amount of data to be handled may be huge, and as the volume of data increases, human errors multiply.</p>
<p class="indent">Secondly, proper disposal of waste is important. Infectious or potentially infectious waste should be incinerated before disposal in a sanitary landfill. On the other hand, radioactive waste should <span class="italic">not</span> be incinerated: it should be buried. Detailed guidelines for disposal <a name="page128"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">128</span></span>of biomedical waste should be collected from appropriate sources depending upon the type of waste generated in the lab.</p>
<div class="sidebar">
<p class="">“Attainment of the needed acceptable accurate lipid and lipoprotein measurements depends upon prevention or control of multiple sources of errors or variation that can exist in <span class="italic">preanalytic, analytic</span> and <span class="italic">postanalytic</span> stages of determination of the reported result. Highly important is to control <span class="italic">nonfasting, posture, diet,</span> and <span class="italic">alcoholic intake</span> in the preanalytic part, elimination of <span class="italic">matrix effects</span> and use of accurate <span class="italic">calibrators</span> in the analytic part, and check for <span class="italic">transcription errors</span> in preparation of reports in the postanalytic part of the measurement of lipids.” (Cooper et al 2002; emphasis added).</p>
</div>
</div><div class="section" id="ch9lev1sec7"><h1 class="title">CLOSING THOUGHTS</h1>
<p class="noindent">Measurement of analytes in the laboratory essentially aims at distinguishing between the biological variability (signal) and the variability inherent in the technique of measurement (noise). Objective evaluation and analysis of both the variabilities is the core of quality control.</p>
<p class="indent">As a reaction to discrepancies and irregularities detected by the Food and Drugs Administration (FDA) of USA in toxicological tests performed by the Industrial Bio-Test Laboratories, FDA proposed Good Laboratory Practice (GLP) guidelines in 1976. The guidelines were finalized in 1978, became effective in 1979, and were modified in 1987 (Cook 2000). Mandatory compliance with these guidelines improves the quality of work; the price to be paid for the improvement is a lot of additional paper work even for those who would follow the guidelines anyway. The GLP guidelines are divided into nine subparts, dealing with general provisions, orgnisation and personnel, facilities, equipment, testing facility operations, test and control articles, protocol for and conduct of a non-clinical laboratory study, records and reports, and disqualification of testing facilities. Broadly speaking, the guidelines are aimed at improving the precision and accuracy of lab tests on one hand, and improving the standards of safety for both the lab personnel and the general public on the other.</p>
<p class="indent">This chapter gives a very superficial coverage to a few selected aspects of laboratory work connected with biomedical research. Details are available in appropriate texts which should be consulted depending on the specific needs of the lab. There is one important component of a significant area of biomedical research, viz. care and handling of laboratory animals, which has been omitted altogether. This subject has been touched upon in <a href="/9788184484175/chapter/ch17" class="ulink-exter">Chapter 17</a>.<a name="page129"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">129</span></span></p>
<p class="aligncenter"><bold>QUESTIONS AND PROBLEMS</bold></p>
<ol style="list-style-type: decimal">
<li><p class="">What is matrix effect?</p></li>
<li><p class="">How may a new analytic test be evaluated?</p></li>
</ol>
<p class="aligncenter"><bold>ANSWERS AND SOLUTIONS</bold></p>
<ol style="list-style-type: decimal">
<li><p class="">Concentration of an analyte being the same, we may get different results if the analyte is in an aqueous medium, in normal serum or in hyperlipidemic serum. This is said to be due to the matrix effect.</p></li>
<li><p class="">Briefly, the same set of samples is analysed by the new method as well as by the old method or a reference method. The results may be plotted as in <a href="#ch9fig4" class="ulink-inter">Figure 9.4</a>. This gives an estimate of the precision and accuracy, and the type of error in accuracy. A convenient way to sum up the comparison is to calculate the correlation coefficient of the estimations by the two methods. But, just a high correlation coefficient is not of much use without an accompanying scatterplot.</p>
<p class=""><div class="figure" id="ch9fig4" data-label="Fig. 9.4"><div class="title"><span class="item-label">Fig. 9.4</span> Comparison of two methods of analysis, A and B. If both the methods give identical readings over the entire range tested (a hypothetical situation), all the values would lie along the dotted line. In practice, the situation is different. If the values lie along line 1, it indicates a random error in the test method if the other method is the reference method. If the deviations from the dotted line are big and lie on either side of the dotted line, the test method has low precision. If the values lie along a line parallel to the dotted line (line 2), it indicates a constant systematic error. If the values lie along line 3, it indicates a proportional systematic error</div><img alt="Fig. 9.4" src="/MediumImage/129-1.jpg"><div class="additional-markup"></div></div></p>
<p class=""><a name="page130"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">130</span></span>In the present context, the scatterplot will tell us the type of data which has generated the high correlation coefficient (<a href="#ch9fig5" class="ulink-inter">Fig. 9.5</a>). Secondly, the scatterplot will tell us the range of concentrations of the analyte over which the evaluation has been done. The range should be wide enough to include most of the readings likely to be encountered in practice. A range wider than that is not necessarily a good thing (<a href="#ch9fig6" class="ulink-inter">Fig. 9.6</a>).</p></li>
</ol>
<div class="figure" id="ch9fig5" data-label="Fig. 9.5"><div class="title"><span class="item-label">Fig. 9.5</span> Comparison of two methods of analysis, A and B, showing four types of hypothetical data which may be associated with high correlation coefficient. One of the methods is the reference method. 1. random error, which may be acceptable; 2. random error, but the number of observations is too small for a decision; 3. random error, but the range of concentrations tested is too small for a decision; and 4. the relationship between the two methods is different at low, medium and high concentrations, which makes the test method unacceptable. The dotted line corresponds to the hypothetical situation when the correlation coefficient is 1.0</div><img alt="Fig. 9.5" src="/MediumImage/130-1.jpg"><div class="additional-markup"></div></div>
<a name="page131"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">131</span></span>
<div class="figure" id="ch9fig6" data-label="Fig. 9.6"><div class="title"><span class="item-label">Fig. 9.6</span> Comparison of two methods of analysis of glucose, A and B, showing hypothetical data plotted in two different ways. One of the methods is the reference method. 1. Data covering a wide range of concentrations (0-1000 mg/dL). The correlation coefficient is likely to be high, and the test method seems to be acceptable. But the catch is that, in practice, most of the samples analysed will have glucose concentrations in a much narrower range (80-300 mg/dL). 2. The same data has been plotted again, using only the observations pertaining to concentrations in the range 50-300 mg/dL. The number of observations is too small to allow a decision. Further, the correlation coefficient is also likely to be lower than in the previous case where the range was 0-1000 mg/dL. The dotted line corresponds to the hypothetical situation when the correlation coefficient is 1.0</div><img alt="Fig. 9.6" src="/MediumImage/131-1.jpg"><div class="additional-markup"></div></div>
<div class="bibliography" id="ch9bib">
<h2 class="title">Bibliography</h2>
<li class="row" id="ch9bib1"><div class="ref-content cell"><a href="#">1.</a> Cook JD. Good laboratory practice (GLP) versus CLIA. Guest essay. 2000. <a href="http://www.westgard.com/guest16.htm" class="weblink">www.westgard.com/guest16.htm</a></div></li>
<li class="row" id="ch9bib2"><div class="ref-content cell"><a href="#">2.</a> Cooper GR, Myers GL, Kimberly MM, Waymack AP. The effects of errors in lipid measurement and assessment. <span class="italic">Curr Cardiol Rep</span> 2002; 4:501-507.</div></li>
<li class="row" id="ch9bib3"><div class="ref-content cell"><a href="#">3.</a> Howerton D, Anderson N, Bosse D, Granade S, Westbrook G. Good laboratory practices for waived testing sites: survey findings from testing sites holding a certificate of waiver under the clinical laboratory improvement amendments of 1988 and recommendations for promoting quality testing. <span class="italic">MMWR Recomm Rep</span> 2005 (Nov 11); 54 (RR-13): 1-25; quiz CE 1-4. PMID: 16280973. Full text available at <a href="http://www.cdc.gov/mmwr/preview/mmwrhtml/rr5413a1.htm" class="weblink">www.cdc.gov/mmwr/preview/mmwrhtml/rr5413a1.htm</a>.</div></li>
<li class="row" id="ch9bib4"><div class="ref-content cell"><a href="#">4.</a> Kaplan LA, Pesce AJ. <span class="italic">Clinical Chemistry: theory, analysis and correlation.</span> St. Louis: Mosby, 2nd edition,1989, <a href="/9788184484175/chapter/ch14" class="ulink-exter">Chapters 14</a>–<a href="/9788184484175/chapter/ch19" class="ulink-exter">19</a>.</div></li>
<li class="row" id="ch9bib5"><div class="ref-content cell"><a href="#">5.</a> Tolonen H, Ferrario M, Kuulasmaa K; WHO MONICA Project. Standardization of total cholesterol measurement in population surveys – pre-analytic sources of variation and their effect on the prevalence of hypercholesterolaemia. <span class="italic">Eur J Cardiovasc Prev Rehabil</span> 2005; 12: 257-267.</div></li>
</div>
</div><div class="section footnotes"><ol class="fn-list table labels"></ol></div></div></div>