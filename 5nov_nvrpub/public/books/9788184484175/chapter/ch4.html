<div class="chapter"><div class="chapter"><h2 class="title">CHAPTER 4. <a name="page24"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">24</span></span>Experimental Design</h2><p><span class="italic">It is better with an approximate answer to a precise problem than an exact answer to a vague question.</span></p><p><span class="italic">— JOHN W TUKEY</span></p><p>Next to the idea, the experimental design is what determines the quality and success of a piece of research. Further, the design with which a study is begun should be followed all the way through unless a deviation is absolutely essential. Mid-course changes in the design end up dividing the study into more than one small studies, each with an inadequately small number of subjects. No amount of statistical jugglery is able to hide this uncomfortable fact. Therefore it is important to thrash out the design thoroughly before starting the study, and then to adhere to it meticulously all the way. The best way to arrive at a satisfactory study design is to combine discussion and introspection: discussion with colleagues and with the statistician, and introspection at a leisurely pace. Just when the design seems perfect, allow a few days of cooling off. During this period, turn the design over and over again in the mind whenever you are relaxed. Soon some flaws and doubts will start surfacing in what looked like a perfect design. Go back to the colleagues and the statistician again with these questions, and you will arrive at a better design (or at least you would know you are making a conscious decision to accept some unavoidable drawbacks!).</p><div class="section" id="ch4lev1sec1"><h1 class="title">UNDERSTANDING THE LANGUAGE</h1>
<p>Before we go into the different types of experimental designs which suit different types of research, it will be good to clarify some of the terms commonly used in relation to the designs.</p>
<div class="section" id="ch4lev2sec1"><h2 class="title">Hypothesis</h2>
<p>A scientist starts research not only with a question but also the probable answer. In fact, the starting point may be a hunch for which no evidence is available, and the research may be so designed as to verify <a name="page25"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">25</span></span>or refute the hunch. A formal statement of the expected answer is called the hypothesis. The hypothesis is formulated in such a way that it is testable. It predicts a relationship between known facts or a difference between groups. The research is expected to determine whether the prediction is true. Sometimes the hypothesis is stated in such a way that the research is expected to determine whether the prediction is false. For example, the hypothesis may state that there is no difference between two groups (null hypothesis). Evidence for a difference between the groups would be considered valid if the hypothesis can be falsified.</p>
<p>A hypothesis is required only if the research examines a relationship or a difference. If the research is designed to build up a data base, a hypothesis is not necessary. For example, a survey to determine the nutritional status of a population does not need a hypothesis. Even if the survey has been undertaken because of the hunch that the population is undernourished, starting with the hypothesis that “the population is undernourished” may prejudice the observations, and is therefore undesirable.</p>
<div class="section" id="ch4lev3sec1"><h3 class="title">Example of a Hypothesis</h3>
<p>Let us start with the observation that addition of water soluble dietary fibre to a meal reduces postprandial glycemia. The scientist may have a hunch that the effect is due to the slowing down of gastric emptying. His hypothesis would read: “Water soluble dietary fibre reduces postprandial glycemia by slowing down gastric emptying.” To test the hypothesis, he may design a study in which each subject receives two meals which are similar in every respect except for the presence or absence of water soluble fibre. Following these meals he would measure postprandial glycemia as well as gastric emptying.</p>
</div>
<div class="section" id="ch4lev3sec2"><h3 class="title">Example of a Null Hypothesis</h3>
<p>Suppose a scientist has a hunch that in metastatic cancer, addition of a psychosocial intervention to conventional therapy may make the patient feel better but would not prolong life. His hypothesis would read: “In metastatic breast cancer, the survival time of patients receiving a psychosocial intervention is the same as that of patients not receiving such an intervention.” Such a hypothesis was actually examined in a study, and the hypothesis falsified (Spiegel et al, 1989).<a name="page26"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">26</span></span></p>
</div>
</div>
<div class="section" id="ch4lev2sec2"><h2 class="title">Population</h2>
<p>A population consists of <span class="italic">all</span> the people in whom the researcher is interested, e.g. <span class="italic">all</span> the children between age 5 and 12 in India. A population need not consist only of people: it may consist of institutions or objects, e.g. <span class="italic">all</span> non-government organizations in India, or <span class="italic">all</span> the syringes in All India Institute of Medical Sciences.</p>
</div>
<div class="section" id="ch4lev2sec3"><h2 class="title">Sample</h2>
<p>Although the researcher is interested in a population, he cannot study the whole population (the number in the population is usually abbreviated as <span class="italic">N</span>). Therefore he studies only a part of the population: the part studied is called the sample. From observations made on the sample, conclusions are drawn about the whole population: this process is called generalization. Whether the generalization is valid depends on the sample: hence the importance of the sampling procedure and the sample size (usually abbreviated as <span class="italic">n</span>). In order to tempt customers, fruit sellers often provide a sample slice of fruit. The slice is invariably sweet. From this observation, the fruit seller makes the generalization that all the fruits in his shop are sweet. Since the fruit seller is interested in selling fruits rather than knowing the truth about the population of fruits in his shop, he adopts a sampling procedure which would maximize the chances of getting a sweet sample. Such a sample is called a biased sample. The researcher, on the other hand, aims at a representative sample. Although there are several methods for getting representative samples, no method guarantees a truly representative sample. Therefore there is always scope for a sampling error. How much the sampling error is can also never be found out precisely, because that would require studying the entire population. If we could study the entire population, why would we need a sample in the first place! Notwithstanding all these uncertainties, reasonably representative samples can be obtained by using one of the methods discussed below. Which method exactly to use depends on the nature of the study and the circumstances of the investigators.</p>
<div class="section" id="ch4lev3sec3"><h3 class="title">Incidental Samples</h3>
<p>These are convenient samples, and therefore commonly used. For example, if we wish to do a study on bronchial asthma, we may study all the patients who volunteer for the study from amongst those who come to our hospital for treatment. We would like to generalize the <a name="page27"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">27</span></span>results of our study to all patients of bronchial asthma, but the generalization may be questionable because the sample is not truly representative. First, only patients from a certain geographical area belonging to a certain socioeconomic level may seek treatment from our hospital. Secondly, the patients who volunteer may differ systematically in some relevant characteristics from those who refuse to volunteer. Although such studies will continue because the better alternatives are much more inconvenient, these limitations should be kept in mind while generalizing from the observations.</p>
</div>
<div class="section" id="ch4lev3sec4"><h3 class="title">Random Samples</h3>
<p>A random sample is one in which every member of the population has an equal chance of being selected for the study. Random sampling involves two basic steps:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Preparing a list of all members of the population in which each member is serially numbered</p></li>
<li><p>Selecting members having certain numbers for the sample by tossing a coin, or using a dice, or random number tables, or random numbers generated by a computer.</p></li>
</ol>
<p>Random sampling is excellent in theory but very difficult in practice. It is almost impossible to have a list of the population, even if the population is restricted, e.g. all those above age 20 having non-insulin dependent diabetes mellitus (NIDDM) in the city of Delhi. Further, we cannot force a person to volunteer for the study just because he happens to bear a certain number in our list. Therefore randomization is generally used only for allocating subjects to a particular group in a study. Thus the sample may be incidental, but allocation to the control and experimental groups may be randomized.</p>
</div>
<div class="section" id="ch4lev3sec5"><h3 class="title">Systematic Samples</h3>
<p>In this method, every 5th or 10th subject is selected for the sample. Whether we take every alternative case or every 100th case would depend on the sample size required in relation to the numbers available. The quality of a systematic sample may be further improved by selecting the first case randomly. This method also gives a fairly representative sample but has difficulties similar to those discussed in relation to random sampling.</p>
</div>
<div class="section" id="ch4lev3sec6"><h3 class="title">Sample Size</h3>
<p>A judiciously determined sample size is an important part of a good research study. Too small a sample size does not allow valid <a name="page28"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">28</span></span>generalization, and may not allow even a clear and valid conclusion. On the other hand, too large a sample size is a waste of time and other resources. Also, too large a sample is ethically inappropriate, specially in animal experiments.<sup><a href="#ch4fn1" class="ulink-inter">1</a></sup> There is no absolute rule for the correct sample size. Statisticians can calculate the minimum sample size <span class="italic">after</span> some data has been collected. If the experimental group shows a marked difference as compared to the controls, a small sample size may be enough. It takes a much larger sample to prove a small effect or to conclude that an intervention has no effect. Therefore it is good to do a pilot study before calculating the sample size. Alternatively, if similar previous studies are available, their data may be used for calculation of the minimum sample size. The standard method to calculate the sample size is to do a power analysis. For those whose mathematics is not very good, power calculators are available online for determining the sample size required for achieving a certain power. In general, a power above 0.80 is considered acceptable.</p>
</div>
</div>
<div class="section" id="ch4lev2sec4"><h2 class="title">External Validity</h2>
<p>As the term indicates, it refers to the extent to which results of the study are likely to hold true outside the study. On that would depend how far it is justified to generalize the results of the study. There are two types of external validity: population validity and ecological validity.</p>
<div class="section" id="ch4lev3sec7"><h3 class="title">Population Validity</h3>
<p>Every study aims to know a population but studies only a sample. The extent to which the results of the study can be generalized to the population is called population validity. It depends on the sample size, the extent to which the sample is truly a representative sample (which in turn depends on the sampling method), and the outcome measures used. It may not be reasonable to extrapolate the results of a study on soldiers to the general population which is physically much less active if the principal outcome measure is lipoprotein profile. It also depends on the quality of the study design. Two features of study designs may be mentioned here. First, the investigators may unintentionally transmit their expectations to the subject (expectancy, or Rosenthal effect).</p>
<p>_____________________</p>
<p><sup class="footnote" id="ch4fn1">[<a href="#d1e1825">4</a>]</sup></p>
<p><a name="page29"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">29</span></span>This may be prevented by making the study double blind. Second, the subjects in the control group may improve simply because of the attention they receive (Hawthorn effect). This effect cannot be eliminated but may be quantified by making the study placebo controlled (<a href="/9788184484175/chapter/ch3" class="ulink-exter">Chapter 3</a>). An interesting phenomenon once occurred in a study in which the effect of an iron supplement was being studied on the hemoglobin levels in the community. Surprisingly, even the control group also showed a statistically significant rise in hemoglobin levels. Since it was considered unlikely that attention would by itself raise hemoglobin levels, the matter was explored further. A plausible explanation that was arrived at was as follows. The control group was receiving a monetary incentive as compensation for not being given the supplement. The group was using the incentive to buy some green vegetables (such as coriander, mint and chillies) to prepare chutney to make the food more palatable. The iron and vitamin content of these vegetables was possibly responsible for the rise in hemoglobin level.</p>
</div>
<div class="section" id="ch4lev3sec8"><h3 class="title">Ecological Validity</h3>
<p>Ecological validity refers to the fact that the results of a study are valid only under the specific conditions of the study. They may not hold good under a different set of studies. For example, bottle feeding worked reasonably well in western countries for several decades. But when bottle feeding was popularized on the basis of these observations in Asia and Africa the results were disastrous because the conditions differed in two important respects. First, the hygiene was poor because the environmental temperature is higher in the tropics and every house does not have a refrigerator in developing countries. Therefore the bottle-fed children in the tropics repeatedly got gastrointestinal infections. Secondly, the mothers could not afford to give the babies adequate quantity of feed. Therefore they diluted the feed excessively, thereby leading to deficient energy intake.</p>
</div>
</div>
<div class="section" id="ch4lev2sec5"><h2 class="title">Controls</h2>
<p>Controls are devices for controlling the variables which it is desirable, but not possible, to keep constant. Ideally, every variable which could affect the outcome should be constant except the one being studied. For example, if we wish to study the effect of walnuts on serum cholesterol levels, other variables such as the rest of the diet, alcohol intake, smoking, exercise, and possibly several other unknown and uncontrollable factors should be kept constant. Diet, alcohol intake, smoking and exercise are kept constant throughout the study. The <a name="page30"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">30</span></span>remaining factors are taken care of by having a control group. The two groups are made as similar as possible except that only one of the groups consumes walnuts.</p>
<p>There are several other types of controls in biomedical research. Some of these have been illustrated below by means of examples.</p>
<div class="section" id="ch4lev3sec9"><h3 class="title">Example 1</h3>
<p>Suppose we wish to study the effect of removing a part of the brain. If several experiments consistently show that removing that part of the brain lowers the blood pressure, a natural conclusion would be that the part removed normally prevents the blood pressure from falling. However, questions could be raised whether the fall in blood pressure observed is a specific effect of removing that part of the brain, or:</p>
<ol style="list-style-type: lower-alpha">
<li><p>is it a delayed effect of the anaesthetic agent employed, or</p></li>
<li><p>is it the effect of the operative procedure, or</p></li>
<li><p>is it the non-specific effect of removing any part of the brain.</p></li>
</ol>
<p>Therefore, in addition to the experiment in which the part of the brain under study is removed, we also need to do experiments in which:</p>
<ol style="list-style-type: decimal">
<li><p>the effect of only the anaesthetic agent on the animal is observed for the duration of the experiment,</p></li>
<li><p>a sham operation is done, i.e. the entire operative procedure is gone through except that the brain is left intact, and</p></li>
<li><p>instead of the part of the brain under study, a neighbouring part of the brain is removed.</p></li>
</ol>
<p>The above three types of experiments are controls. Of these, the first control may not be necessary if the anaesthetic agent has been used earlier in a variety of experiments of comparable duration on the same species without any fall in blood pressure having been reported.</p>
</div>
<div class="section" id="ch4lev3sec10"><h3 class="title">Example 2</h3>
<p>Suppose we wish to study the effect of stimulating a part of the brain electrically. If it is the same part of the brain which was removed in the above experiment, and we observe a rise in blood pressure, the results of the two experiments are consistent with each other. Hence our previous conclusion is strengthened. Thus the two experiments are complementary. However, the stimulation experiment is itself <a name="page31"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">31</span></span>amenable to alternative explanations, i.e. the observed rise in blood pressure may be due to:</p>
<ol style="list-style-type: lower-alpha">
<li><p>the effect of the operative procedures, or</p></li>
<li><p>stimulation of neighbouring areas due to spread of the electrical stimulus, or</p></li>
<li><p>stimulation of nerve fibres passing through the region stimulated.</p></li>
</ol>
<p>Therefore, in addition to the experiment in which the part of the brain under study is stimulated, we also need to do control experiments in which:</p>
<ol style="list-style-type: lower-alpha">
<li><p>a sham operation is done, i.e. the entire operative procedure is gone through, including the introduction of the electrode, except that the stimulus is not delivered,</p></li>
<li><p>neighbouring areas of the brain are stimulated, and</p></li>
<li><p>the stimulus is delivered to areas of the brain which send efferent fibres through the part of the brain under study.</p></li>
</ol>
<p>If no rise in blood pressure is observed in the above control experiments, it further supports our conclusion. Suppose a rise in blood pressure is observed also in experiment (b) above. Then an important consideration would be the threshold strength of the stimulus required for getting the response. The area where the threshold is the lowest would be the one to which the blood pressure-raising effect may be attributed.</p>
</div>
<div class="section" id="ch4lev3sec11"><h3 class="title">Example 3</h3>
<p>Suppose we wish to study the effect of injecting a neurotransmitter in some area of the brain. After such as experiment, the observed effect may be specific to the experimental procedure, but it could equally be:</p>
<ol style="list-style-type: lower-alpha">
<li><p>a non-specific effect of an injection into that part of the brain, or</p></li>
<li><p>a non-specific effect of the chemical injected anywhere in the brain.</p></li>
</ol>
<p>Examination of these alternative explanations would require control experiments in which:</p>
<ol style="list-style-type: lower-alpha">
<li><p>only the vehicle (usually saline) is injected into the same part of the brain, and</p></li>
<li><p>the same chemical is injected elsewhere in the brain.<sup><a href="#ch4fn2" class="ulink-inter">2</a></sup></p></li>
</ol>
<p>___________________</p>
<p><sup class="footnote" id="ch4fn2">[<a href="#d1e1991">5</a>]</sup></p>
<a name="page32"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">32</span></span>
</div>
<div class="section" id="ch4lev3sec12"><h3 class="title">Example 4</h3>
<p>Suppose we wish to study the effect of yogurt on gut immunity. After such a study, the doubt would remain whether the effect is due to the bacteria in yogurt, or due to the other constituents of yogurt. One solution is to have a control group that receives an equivalent amount of milk because, except for the bacteria, the other constituents of milk and yogurt are similar. Alternatively, the control group may receive only an equivalent dose of bacteria in the form of a culture. It would be ideal to have both types of control groups.</p>
</div>
<div class="section" id="ch4lev3sec13"><h3 class="title">Why Controls?</h3>
<p>Controls have at least two functions. First, they are essential for reasonably valid results. Without the controls, as we have seen above, every experimental observation is amenable to several alternative explanations. Controls take care of at least some of the obvious alternative explanations. Secondly, they help us in estimating the size of the effect. For example, in double blind clinical trials in depression, it has been found that the placebo is also nearly half as effective as a good anti-depressant. Based on this, we may be able to say that 40% of the effect of a given anti-depressant is placebo effect and 60% of the effect is specifically because of its biochemical properties.</p>
<div class="sidebar">
<p>If one doubts the necessity of controls, reflect on the statement: “It has been conclusively demonstrated by hundreds of experiments that the beating of tom-toms will restore the sun after an eclipse.”</p>
<p><span class="italic">E. BRIGHT WILSON, Jr.</span></p>
</div>
</div>
</div>
<div class="section" id="ch4lev2sec6"><h2 class="title">Independent Variable</h2>
<p>An independent variable is the variable deliberately altered by the investigator. In a graph, it is usually plotted on the X-axis. For example, in an experiment on the effect of temperature on the activity of an enzyme, the temperature is the independent variable (<a href="#ch4fig1" class="ulink-inter">Fig. 4.1</a>). In some studies, the independent variable may not be altered by the investigator. For example, in a study on pharmacokinetics, the concentration of a drug in the blood may be studied at different points in time following the administration of a drug. Here time is the independent variable (<a href="#ch4fig2" class="ulink-inter">Fig. 4.2</a>).<a name="page33"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">33</span></span></p>
<div class="figure" id="ch4fig1" data-label="Fig. 4.1"><div class="title"><span class="item-label">Fig. 4.1</span> The enzyme activity (dependent variable) depends on the temperature (independent variable)</div><img alt="Figure 33-1" src="XML/9788184484175/Chapters/images/33-1.jpg"><div class="additional-markup"></div></div>
<div class="figure" id="ch4fig2" data-label="Fig. 4.2"><div class="title"><span class="item-label">Fig. 4.2</span> The blood level of the drug (dependent variable) depends on the time elapsed (independent variable) after administration of the drug</div><img alt="Figure 33-2" src="XML/9788184484175/Chapters/images/33-2.jpg"><div class="additional-markup"></div></div>
</div>
<div class="section" id="ch4lev2sec7"><h2 class="title">Dependent Variables</h2>
<p>Dependent variables, or outcome measures, are the variables being studied. They are so called because they depend on alterations in the independent variable. In the above examples, enzyme activity and blood level of the drug are dependent variables. As you would observe, dependent variables are usually plotted on the Y-axis.</p>
<p>The term outcome measures emphasizes that only some of the dependent variables may be of primary interest to the investigator. For example, in a study on a drug, therapeutic effects as well as all side effects are dependent variables. But the outcome measures may be only the therapeutic effects and serious side effects. The focus is further narrowed down by using the term <bold>principal outcome measures.</bold><a name="page34"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">34</span></span></p>
</div>
<div class="section" id="ch4lev2sec8"><h2 class="title">Extraneous Variables</h2>
<p>Extraneous variables are factors other than the independent variable which may affect the dependent variables. Extraneous variables are sometimes called confounding factors because they vitiate, or confound, the results. As discussed above, in a typical study, some of the extraneous variables are controlled, and the effect of others is estimated by having appropriate control groups.</p>
</div>
<div class="section" id="ch4lev2sec9"><h2 class="title">Internal Validity</h2>
<p>The aim of most experimental studies is to examine the extent to which the chosen independent variable influences the dependent variable. We have seen how extraneous variables may enter the picture and vitiate the study, and how the influence of extraneous variables may be minimized. The internal validity of a study depends on the degree to which the influence of extraneous variables has been minimized. If the influence of extraneous variables is completely eliminated (which is seldom possible), the internal validity is 100%, i.e. at least for that study the change in the dependent variable is entirely attributable to manipulation of the independent variable by the investigator.</p>
<p>Controlling for extraneous variables is specially difficult in epidemiological studies. For example, a descriptive study may find a high correlation between smoking and coronary heart disease (CHD). The association does not prove that smoking causes CHD because smokers and non-smokers may differ from each other in many other relevant factors, e.g. mental stress. Those who are under stress are also more likely to smoke. Therefore it may be difficult to say whether the risk for CHD is increased by stress or smoking or by both independently.<sup><a href="#ch4fn3" class="ulink-inter">3</a></sup> Therefore the internal validity of epidemiological studies is generally low. They are, therefore, good for getting several plausible hypotheses, but not for discovering definitive cause-effect relationships. The hypotheses may then be tested by conducting well-controlled experimental studies.</p>
<p>There is often a conflict between internal and external validity. For example, if a trial has to be conducted for comparing two modes of treatment, it is usually considered ideal to give these treatments to two groups of patients who are assigned to the groups through randomization. This process makes it likely that the two groups will be comparable in every respect, which is important for high validity.</p>
<p>____________________</p>
<p><sup class="footnote" id="ch4fn3">[<a href="#d1e2100">6</a>]</sup></p>
<p><a name="page35"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">35</span></span>The validity which improves by randomization is internal validity because it makes any observed difference between the two groups attributable to the difference in the efficacy of the two modes of treatment. But such a study does not necessarily have high external validity because in the real world the patient has a choice of taking one treatment or the other, and he chooses the treatment in which he has greater confidence, or the treatment which is more convenient, painless or affordable. Therefore a research study which offers the choice of treatment to the patient instead of random allocation has better external validity. Further, it is also ethically more sound because it does not impose a particular treatment on the patient.</p>
</div>
</div><div class="section" id="ch4lev1sec2"><h1 class="title">DESIGN FOR DESCRIPTIVE RESEARCH</h1>
<p>Research which is designed to collect data is called descriptive or non-experimental research. In such research, there is no intervention by the research worker. The design for descriptive research is relatively simple (<a href="#ch4fig3" class="ulink-inter">Fig. 4.3</a>). It involves basically determining what has to be studied in whom: pulmonary function in miners, hepatic function in patients on antitubercular therapy, hemoglobin level in normally nourished women during pregnancy, or the prevalence of diabetes mellitus among those above 20 years of age in the city of Delhi. Both the variable to be studied, and the population to be studied should be defined precisely. If the population to be studied is too large or inaccessible, as is usually the case, an appropriate sampling technique should be selected. Having done that, the study may begin.</p>
<p>Although descriptive studies seem simple, getting a large enough representative sample is often not easy. Further, the very act of doing the study may affect the results. For example, when obese persons are asked what they eat during the day, they have a tendency to under-report. If tidal volume is determined using a mouth piece and nose clip, it is unlikely to be the same as during natural breathing.<sup><a href="#ch4fn4" class="ulink-inter">4</a></sup></p>
<div class="figure" id="ch4fig3" data-label="Fig. 4.3"><div class="title"><span class="item-label">Fig. 4.3</span> Design of a descriptive study</div><img alt="Figure 35-1" src="XML/9788184484175/Chapters/images/35-1.jpg"><div class="additional-markup"></div></div>
<p>_____________________</p>
<p><sup class="footnote" id="ch4fn4">[<a href="#d1e2141">7</a>]</sup></p>
<a name="page36"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">36</span></span>
</div><div class="section" id="ch4lev1sec3"><h1 class="title">DESIGN FOR EXPERIMENTAL RESEARCH</h1>
<p>In experimental research, the research worker administers an intervention and observes its effect. In principle, the design of an experimental study is simple (<a href="#ch4fig4" class="ulink-inter">Fig. 4.4</a>). But various factors may necessitate a complex design.</p>
<div class="figure" id="ch4fig4" data-label="Fig. 4.4"><div class="title"><span class="item-label">Fig. 4.4</span> Design of an experimental study</div><img alt="Figure 36-1" src="XML/9788184484175/Chapters/images/36-1.jpg"><div class="additional-markup"></div></div>
<div class="section" id="ch4lev2sec10"><h2 class="title">Assignment to Groups</h2>
<p>The experimental and control groups should be as similar as possible with the difference that only the experimental group is administered the intervention. The similarity of the two groups is generally sought to be achieved by random allocation. Randomization makes it likely that the two groups are similar but does not guarantee it. To solve this problem, first we need to determine the crucial factors with respect to which the two groups should be well-matched. For example, it may not be relevant to the study that the two groups should be similar to each other with respect to distribution of height. Therefore it may not matter if in one group, 20 out of 50 subjects are tall, whereas in the other group only 6 out of 50 subjects are tall. Once the crucial factors have been determined, first like pairs of subjects may be formed, and then the pairs randomly assigned to the two groups. For example, if the effect of the intervention is likely to be different in smokers and non-smokers. Then smokers should be paired with smokers and non-smokers should be paired with non-smokers. Suppose there are 12 pairs of smokers and 38 pairs of non-smokers. Each pair should be numbered. Then the pairs should be assigned <a name="page37"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">37</span></span>randomly to the experimental and control groups. This procedure will ensure randomization as well as equal numbers of smokers/non-smokers in the experimental and control groups.</p>
</div>
<div class="section" id="ch4lev2sec11"><h2 class="title">Pre-test/Post-test vs. Post-test Only Designs</h2>
<p>In order to assess the effect of an intervention, the dependent variable is measured before and after the intervention in the experimental group, and at the corresponding points in time also in the control group (<a href="#ch4fig5" class="ulink-inter">Fig. 4.5</a>). This is the pre-test/post-test design and makes sense. But there are studies in which only post-test observations are made although it apparently does not make sense. For example, suppose a study has to be designed to answer the question whether administration of prophylactic antibiotics postoperatively reduces postoperative infection. For such a study, the design would be as shown in <a href="#ch4fig6" class="ulink-inter">Fig. 4.6</a>. Here the observations would consist of evidence of postoperative infection, and would be expressed as prevalence.</p>
<div class="figure" id="ch4fig5" data-label="Fig. 4.5"><div class="title"><span class="item-label">Fig. 4.5</span> Schematic representation of the pre-test/post-test design. OBS 1 and 2, initial observations; OBS 3 and 4, final observations</div><img alt="Figure 37-1" src="XML/9788184484175/Chapters/images/37-1.jpg"><div class="additional-markup"></div></div>
<div class="figure" id="ch4fig6" data-label="Fig. 4.6"><div class="title"><span class="item-label">Fig. 4.6</span> ‘Post-test only’ design to assess the value of prophylactic antibiotics given post-operatively. Opn, surgical operation</div><img alt="Figure 37-2" src="XML/9788184484175/Chapters/images/37-2.jpg"><div class="additional-markup"></div></div>
<p><a name="page38"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">38</span></span>Suppose there are 100 patients in the experimental group and only three show evidence of postoperative infection: the prevalence of the complication is 3%. Suppose the prevalence of postoperative infection in the control group is 12%. Obviously, here there is scope for only one set of observations after the intervention (antibiotics). Whether 3% is significantly lower than 12% can be assessed by chi-square test (<a href="/9788184484175/chapter/ch5" class="ulink-exter">Chapter 5</a>).</p>
</div>
<div class="section" id="ch4lev2sec12"><h2 class="title">Parallel vs. Cross-over Design</h2>
<p>If the experimental and control groups remain distinct throughout the study, and the study ends with post-test observations as discussed above (<a href="#ch4fig5" class="ulink-inter">Fig. 4.5</a>), it is called a parallel design. However, the study could be continued further with the groups crossing over, i.e. the experimental group now receiving control treatment, and what was the control group earlier now receiving experimental treatment (<a href="#ch4fig7" class="ulink-inter">Fig. 4.7</a>). In this design, we have six sets of observations (OBS. 1-6, <a href="#ch4fig7" class="ulink-inter">Fig. 4.7</a>). OBS. 1 and 2 provide baseline data, and their comparison tells us whether Groups 1 and 2 are really well-matched. Further, OBS. 2 and 4 ideally should not be significantly different. If they are, it is a stimulus for exploring extraneous factors (e.g. change of season) possibly responsible for the difference. OBS. 4 and 5 give us the values after a period of ‘no intervention’ in the two groups: these may be pooled to get the control values. Similarly OBS. 3 and 6 give us the values after a period of intervention: these may be pooled to get the experimental values.<sup><a href="#ch4fn5" class="ulink-inter">5</a></sup> However, there is one flaw in this design. We are presuming that in Group 1 the period of ‘no intervention’ is long enough for the effect of intervention to disappear. The presumption may not be always valid.</p>
<div class="figure" id="ch4fig7" data-label="Fig. 4.7"><div class="title"><span class="item-label">Fig. 4.7</span> Cross-over design</div><img alt="Figure 38-1" src="XML/9788184484175/Chapters/images/38-1.jpg"><div class="additional-markup"></div></div>
<p>________________________</p>
<p><sup class="footnote" id="ch4fn5">[<a href="#d1e2244">8</a>]</sup></p>
<p><a name="page39"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">39</span></span>This snag can be overcome by inserting a ‘wash out period’ before crossing over (<a href="#ch4fig8" class="ulink-inter">Fig. 4.8</a>). During the wash out period, the subjects are not supervised and can do anything that they might do if they were not on a study. In this design, we have eight sets of observations (OBS. 1-8, <a href="#ch4fig8" class="ulink-inter">Fig. 4.8</a>). OBS. 2 and 5 are the initial values for the control phase, and may be pooled. OBS. 4 and 7 are the final values for the control phase, and may be pooled. Thus we have a pair of pooled values to compare and find out if any significant change took place during the control phase, i.e. without the intervention. Similarly, pooling OBS. 1 and 6 gives us the initial values for the intervention phase, and pooling OBS. 3 and 8 gives us the final values for the intervention phase.<sup><a href="#ch4fn6" class="ulink-inter">6</a></sup> Thus the 8 observations get reduced to 4 values and may be analyzed like the 4 observations in the parallel design (<a href="#ch4fig3" class="ulink-inter">Fig. 4.3</a>). If the idea is to have just 4 sets of observations, what is the advantage in prolonging and complicating the study by introducing the ‘cross-over’?<sup><a href="#ch4fn7" class="ulink-inter">7</a></sup> The advantages are:</p>
<div class="figure" id="ch4fig8" data-label="Fig. 4.8"><div class="title"><span class="item-label">Fig. 4.8</span> Cross-over design with wash out period</div><img alt="Figure 39-1" src="XML/9788184484175/Chapters/images/39-1.jpg"><div class="additional-markup"></div></div>
<ol style="list-style-type: lower-alpha">
<li><p>It increases the subjects in each group because now every subject is participating in the control phase as well as experimental phase.</p></li>
<li><p>Any discrepancy due to Group 1 and 2 being not well-matched does not matter, again because every subject finally participates in the control phase as well as experimental phase.</p></li>
</ol>
<div class="section" id="ch4lev3sec14"><h3 class="title">Lead-in Period</h3>
<p>We have seen above the importance of having well-matched experimental and control groups. We have also seen that in spite of randomization, the two groups may turn out to be not well-matched.</p>
<p>______________________</p>
<p><sup class="footnote" id="ch4fn6">[<a href="#d1e2301">9</a>]</sup></p>
<p><sup class="footnote" id="ch4fn7">[<a href="#d1e2308">10</a>]</sup></p>
<p><a name="page40"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">40</span></span>However, the two groups may not be intrinsically as different as they seem. The differences may be due to extraneous factors which have been foreseen and controlled for both groups during the study period. Therefore sometimes a lead-in period is built into the experimental design at the beginning of the study. During the lead-in period, neither group receives the intervention, but all the extraneous factors which it is intended to control during the study are controlled. In short, both groups are treated like the control group during the lead-in period (usually 1-2 wk), the baseline data is collected, and the intervention is started in the experimental group. It is frequently observed that the two groups are more similar to each other (better matched) at the end of the lead-in period than at its beginning. The baseline data for interpretation of the study is that collected at the end of the lead-in period. Besides eliminating some of the dissimilarities between groups (by reducing inter-individual variation), the lead-in period also gives the subjects time to adapt to the requirements of the study, such as staying in the metabolic ward or travelling to the laboratory, regulating diet and physical activity, undergoing a test, etc. If a lead-in period is built into the experimental design, randomization into groups should be after the lead-in period. This ensures that drop-outs, if any, during the lead-in period do not impair the benefits of randomization.</p>
</div>
</div>
<div class="section" id="ch4lev2sec13"><h2 class="title">Design for a Study with More than One Independent Variable</h2>
<p>A study need not have only one independent variable at a time. For example, energy intake as well as energy expenditure both affect body weight. Suppose a study has to be conducted to compare the efficacy of energy restriction and physical exercise for weight reduction in obesity. For this purpose, the subjects may be randomized into four groups:</p>
<p>Group 1 Energy restriction only</p>
<p>Group 2. Physical exercise only</p>
<p>Group 3. Energy restriction and physical exercise</p>
<p>Group 4. Neither energy restriction nor physical exercise (control)</p>
<p>Such a design is called a factorial design.</p>
<p>If the number of independent variables is very large, it can present problems. For example, if we wish to study the effect of fat (F), protein (P), water soluble fibre (WSF) and water insoluble fibre (WIF) on postprandial glycemia, the following meals would be required for studying the independent as well as additive effects of all these variables:<a name="page41"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">41</span></span></p>
<ol style="list-style-type: decimal">
<li><p>Glucose (control)</p></li>
<li><p>Glucose + F</p></li>
<li><p>Glucose + P</p></li>
<li><p>Glucose + WSF</p></li>
<li><p>Glucose + WIF</p></li>
<li><p>Glucose + F + P</p></li>
<li><p>Glucose + F + WSF</p></li>
<li><p>Glucose + F + WIF</p></li>
<li><p>Glucose + P + WSF</p></li>
<li><p>Glucose + P + WIF</p></li>
<li><p>Glucose + WSF + WIF</p></li>
<li><p>Glucose + F + P + WSF</p></li>
<li><p>Glucose + F + P + WIF</p></li>
<li><p>Glucose + F + P + WSF + WIF</p></li>
</ol>
<p>It will be unreasonable to expect any subject to undergo 14 meal tolerance tests. Further if only a few of these meals are tested on a small number of subjects each, the results would be affected so much by inter-individual and intra-individual variation that they cannot be pooled for purposes of interpretation. In such cases, a series of sets may be made. A set should include 4-5 meals such that each set includes the control meal and at least one meal in common with at least one more set. Then the subjects may be randomized to undergo one set of meal tolerance tests. Such a design is called an incomplete block design.</p>
</div>
<div class="section" id="ch4lev2sec14"><h2 class="title">Design for a Study with More than One Dependent Variable</h2>
<p>A study may have several dependent variables. Even the principal outcome measure may consist of more than one variable. For example, in a study on the management of bronchial asthma, changes in pulmonary function, symptom score and frequency of hospitalization may all be important dependent variables. In such cases, the significance of changes in various dependent variables may be evaluated separately.</p>
</div>
</div><div class="section" id="ch4lev1sec4"><h1 class="title">CONCLUSION</h1>
<p>This chapter is merely an introduction to some general aspects of research designs. Special features of designs relevant to clinical, epidemiological and other categories of medical research will be dealt with in subsequent chapters.<a name="page42"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">42</span></span></p>
<p><bold>PROBLEM</bold></p>
<ol style="list-style-type: decimal">
<li><p>A student was shown the following graph (<a href="#ch4fig9" class="ulink-inter">Fig. 4.9</a>) drawn on the basis of postprandial blood glucose and insulin levels achieved at different points in time during an oral glucose tolerance test.</p></li>
</ol>
<div class="figure" id="ch4fig9" data-label="Fig. 4.9"><div class="title"><span class="item-label">Fig. 4.9</span> Graph showing relationship between serum insulin and serum glucose (wrong way)</div><img alt="Figure 42-1" src="XML/9788184484175/Chapters/images/42-1.jpg"><div class="additional-markup"></div></div>
<p>He described the graph as follows:</p>
<p>“As the insulin level rises, the glucose level also rises. Hence insulin has a hyperglycemic effect”. His conclusion is obviously wrong. Where is the problem?</p>
<p><bold>SOLUTION</bold></p>
<ol style="list-style-type: decimal">
<li><p>The problem is with the person who plotted the graph. Here insulin is the dependent variable, and should have therefore been plotted along the Y-axis. The student interpreted the graph considering insulin to be the independent variable and glucose the dependent variable because convention has conditioned us to consider the variable along the Y-axis as the dependent variable. If the same data were plotted with the axes exchanged, it would look as follows (<a href="#ch4fig10" class="ulink-inter">Fig. 4.10</a>).<a name="page43"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">43</span></span></p></li>
</ol>
<div class="figure" id="ch4fig10" data-label="Fig. 4.10"><div class="title"><span class="item-label">Fig. 4.10</span> Graph showing relationship between serum insulin and serum glucose (correct way)</div><img alt="Figure 43-1" src="XML/9788184484175/Chapters/images/43-1.jpg"><div class="additional-markup"></div></div>
<p>A student looking at this graph is likely to interpret it as follows: “As the glucose level rises, the insulin level also rises. Hence glucose has the effect of releasing insulin from the B cells of the pancreas”. This conclusion is obviously correct.</p>
<div class="bibliography" id="ch4bib">
<h2 class="title">Bibliography</h2>
<li class="row" id="ch4bib1"><div class="ref-content cell"><a href="#">1.</a> Andrade C. Confounding. <span class="italic">Indian J Psychiatry</span> 2007; 49:129-131.</div></li>
<li class="row" id="ch4bib2"><div class="ref-content cell"><a href="#">2.</a> Grimes DA, Schulz KF. Bias and causal associations in observational research. <span class="italic">Lancet</span> 2002; 359:248-252.</div></li>
<li class="row" id="ch4bib3"><div class="ref-content cell"><a href="#">3.</a> Herrera L. The design of experiments in medical research. <span class="italic">Journal of the Indian Medical Profession</span> 1960; 6:3029-3032,3040.</div></li>
<li class="row" id="ch4bib4"><div class="ref-content cell"><a href="#">4.</a> Spiegel D, Bloom JR, Kraemer HC, Gottheil E. Effect of psychosocial treatment on survival of patients with metastatic breast cancer. <span class="italic">Lancet</span> 1989; 2: 888-891.</div></li>
</div>
</div></div></div>