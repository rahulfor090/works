<div class="chapter"><div class="chapter"><h2 class="title">CHAPTER 5. <a name="page44"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">44</span></span>Presentation, Analysis and Interpretation of Data</h2><p><span class="italic">Observations are always correct; interpretations may not be.</span></p><p><span class="italic">— BK ANAND</span></p><p>After you have prepared a design which comes as close to perfection as it possibly can, the next step is to actually do the study. How to do the study cannot be learnt from this book. However, some general tips for doing different categories of medical research, such as clinical, laboratory or public health research, will be given in the next few chapters. For the moment, we will skip the step of doing the study and go to the next step instead. Every study generates data, and there are some general guidelines for making sense out of the mess which data inevitably consists of. All aspects of handling data belong to the realm of statistics.</p><div class="section" id="ch5lev1sec1"><h1 class="title">TYPES OF DATA</h1>
<p>Data is generally in the form of numerical figures. All numerical data can be classified into the following broad categories.</p>
<div class="section" id="ch5lev2sec1"><h2 class="title">Discrete or Discontinuous Data</h2>
<p>This is the type of data which has distinct categories. It is further classified into nominal and ordinal data.</p>
<div class="section" id="ch5lev3sec1"><h3 class="title">Nominal Data</h3>
<p>Here the data consists of unordered categories, e.g. male and female; blood groups A, B, AB or O; etc. Numbers are assigned to the categories only for convenience, e.g. we may have a code for blood groups, A=1, B=2, AB=3 and O=4. Here the value of the numericals 1,2, 3 and 4 has no significance. It will make no sense to find out the ‘mean blood group’ by finding the mean of all the ones, twos, threes and fours in the data! But if 1 occurs 20 times, 2 occurs 30 times, 3 occurs 40 times and 4 occurs 10 times in our data, we can say that in our sample, 20% of the subjects have blood group A, 30% have group B, 40% have group AB, and only 10% have group O.<a name="page45"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">45</span></span></p>
</div>
<div class="section" id="ch5lev3sec2"><h3 class="title">Ordinal Data</h3>
<p>Here the data consists of ordered categories, e.g. Underweight, Normal weight, Overweight and Obese.</p>
</div>
</div>
<div class="section" id="ch5lev2sec2"><h2 class="title">Continuous Data</h2>
<p>Continuous data consists of values which do not fall in distinct categories, e.g. blood pressure. However, we may convert continuous data into discrete data, e.g. by dividing subjects into two categories: those with systolic blood press (SBP) up to 140 mm Hg (normotensives) and those with SBP above 140 mm Hg (hypertensives).</p>
<div class="sidebar">
<h2 class="title">Ratios and related stuff</h2>
<p>Discrete data is often processed to obtain ratios, proportions and percentages. Suppose our sample consists of 30 males and 20 females. We can express it as:</p>
<p><ol style="list-style-type: lower-alpha">
<li><p>the <bold>ratio</bold> of males to females, i.e. 3: 2 or 3/2;</p></li>
<li><p>the <bold>proportion</bold> of males, i.e. 30/50 = 0.6 or the <bold>proportion</bold> of females, i.e. 20/50 = 0.4 or</p></li>
<li><p>the <bold>percentage</bold> of males, i.e. 0.6 × 100 = 60%; or the <bold>percentage</bold> of females, i.e. 0.4 × 100 = 40%</p></li>
</ol></p>
<p>In short, ratio gives the relative frequency of categories; proportion gives the frequency of a category as a fraction of the total sample or population; and percentage is the proportion multiplied by 100.</p>
</div>
</div>
</div><div class="section" id="ch5lev1sec2"><h1 class="title">PRESENTATION OF DATA</h1>
<p>The data, as initially collected, is called raw data. Raw data is usually massive and thoroughly disorganized. Therefore the first step to make sense out of it is to condense it and organize it. Condensation necessarily involves loss of detail. There is no fixed rule about how much detail may be sacrificed in the interest of clarity. That is where the judgement of the investigator plays a crucial role. He has to make sure that the data can be grasped quickly, and yet nothing of importance is lost. The principal tools for presentation of data are Tables and Graphs.</p>
<div class="section" id="ch5lev2sec3"><h2 class="title">Tables</h2>
<p>A typical Table has a structure as shown in <a href="#ch5fig1" class="ulink-inter">Figure 5.1</a>.</p>
<div class="figure" id="ch5fig1" data-label="Fig. 5.1"><div class="title"><span class="item-label">Fig. 5.1</span> A typical Table having three columns and two rows</div><img alt="Figure 45-1" src="XML/9788184484175/Chapters/images/45-1.jpg"><div class="additional-markup"></div></div>
<p><a name="page46"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">46</span></span>Some of the common errors in Tables are that the units of measurement are not mentioned, or what the values represent (e.g. mean and standard deviation) is not told. Journals usually prefer that the data be presented in Tables rather than Graphs because Tables not only generally give more details, but there is also less scope for hiding ugly facts, or misguiding the reader. All the same, Tables are meant to be understood and therefore should be kept small and simple, by breaking a complex Table into two or more Tables, if necessary.</p>
</div>
<div class="section" id="ch5lev2sec4"><h2 class="title">Graphs</h2>
<p>There is nothing like a good Graph to grasp the essence of data at a glance. Therefore Graphs are better than Tables when presenting the work orally or through a poster. Graphs may also be used in a publication to highlight the salient features of the Results. As in case of Tables, Graphs should also be kept simple, the axes should be labelled properly, the units of measurement indicated, and a sufficiently informative legend should be supplied so that the graph is self-explanatory. A few common varieties of graphs are as follows:</p>
<div class="section" id="ch5lev3sec3"><h3 class="title">Bar Graphs/Charts</h3>
<p>Bar charts are used for depicting discrete data. The horizontal axis (X-axis or abscissa) is conventionally used for indicating the categories in which observations fall. The frequency is plotted along the vertical axis (Y-axis or ordinate). In a bar chart, the bars are separated by a distance to indicate that the data is discontinuous. An example of a bar chart is given in <a href="#ch5fig2" class="ulink-inter">Figure 5.2</a>.</p>
</div>
<div class="section" id="ch5lev3sec4"><h3 class="title">Pie Diagram</h3>
<p>If frequency is converted into relative frequency (%), the data may be presented as a pie diagram instead of a bar chart (<a href="#ch5fig3" class="ulink-inter">Fig. 5.3</a>).</p>
</div>
<div class="section" id="ch5lev3sec5"><h3 class="title">Histogram</h3>
<p>Histograms are used for depicting continuous data. A histogram looks like a bar chart but its bars are made to touch each other to indicate that the data is continuous (<a href="#ch5fig4" class="ulink-inter">Fig. 5.4</a>).</p>
</div>
<div class="section" id="ch5lev3sec6"><h3 class="title">Frequency Polygon</h3>
<p>A histogram may be converted into a frequency polygon as shown in <a href="#ch5fig5" class="ulink-inter">Figure 5.5</a>. The advantage of a frequency polygon is that two or more sets of data may be shown in the same diagram and compared (<a href="#ch5fig6" class="ulink-inter">Fig. 5.6</a>).<a name="page47"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">47</span></span></p>
<div class="figure" id="ch5fig2" data-label="Fig. 5.2"><div class="title"><span class="item-label">Fig. 5.2</span> An example of a bar chart: annual outpatient attendance at AIIMS</div><img alt="Figure 47-1" src="XML/9788184484175/Chapters/images/47-1.jpg"><div class="additional-markup"></div></div>
<div class="figure" id="ch5fig3" data-label="Fig. 5.3"><div class="title"><span class="item-label">Fig. 5.3</span> An example of a pie diagram: outpatient attendance in different sections of AIIMS</div><img alt="Figure 47-2" src="XML/9788184484175/Chapters/images/47-2.jpg"><div class="additional-markup"></div></div>
<div class="figure" id="ch5fig4" data-label="Fig. 5.4"><div class="title"><span class="item-label">Fig. 5.4</span> A histogram depicting the systolic blood pressure (SBP) in a sample of healthy 21-30 years olds. The data has been arranged in terms of class intervals with a range of 5 mmHg, viz. 90-94, 95-99, 100-104 mmHg, and so on</div><img alt="Figure 47-3" src="XML/9788184484175/Chapters/images/47-3.jpg"><div class="additional-markup"></div></div>
<a name="page48"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">48</span></span>
<div class="figure" id="ch5fig5" data-label="Fig. 5.5"><div class="title"><span class="item-label">Fig. 5.5</span> This diagram shows how the histogram drawn in <a href="#ch5fig4" class="ulink-inter">Figure 5.4</a> may be converted into a frequency polygon. Here each point corresponds to the mid-point of the class interval. For example, the mid-point of 90-94 mm Hg is 92 mm Hg. SBP, systolic blood pressure</div><img alt="Figure 48-1" src="XML/9788184484175/Chapters/images/48-1.jpg"><div class="additional-markup"></div></div>
<div class="figure" id="ch5fig6" data-label="Fig. 5.6"><div class="title"><span class="item-label">Fig. 5.6</span> Two frequency polygons depicting the systolic blood pressure (SBP) in a sample of healthy 21-30 year olds (A) and 41-50 year olds (B)</div><img alt="Figure 48-2" src="XML/9788184484175/Chapters/images/48-2.jpg"><div class="additional-markup"></div></div>
<p>A frequency polygon also gives us an idea of the distribution. A bell-shaped distribution is considered ‘normal’ (<a href="#ch5fig7" class="ulink-inter">Fig. 5.7</a>). If the distribution is not normal, it may be positively or negatively skewed (<a href="#ch5fig8" class="ulink-inter">Fig. 5.8</a>). An easy way to avoid making a mistake about the direction of skewing is to look at the ‘tail’ (the thin part) of the frequency polygon. The direction in which the tail points gives the direction of the skewing (<a href="#ch5fig9" class="ulink-inter">Fig. 5.9</a>). The importance of distribution will become apparent when we discuss analysis of data. Some of the simpler statistical tests are valid only for normally distributed data.<a name="page49"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">49</span></span></p>
<div class="figure" id="ch5fig7" data-label="Fig. 5.7"><div class="title"><span class="item-label">Fig. 5.7</span> Bell-shaped, ‘normal’, or Gaussian distribution</div><img alt="Figure 49-1" src="XML/9788184484175/Chapters/images/49-1.jpg"><div class="additional-markup"></div></div>
<div class="figure" id="ch5fig8" data-label="Fig. 5.8"><div class="title"><span class="item-label">Fig. 5.8</span> Skewed distribution: A. positive skewing; B. negative skewing</div><img alt="Figure 49-2" src="XML/9788184484175/Chapters/images/49-2.jpg"><div class="additional-markup"></div></div>
<div class="figure" id="ch5fig9" data-label="Fig. 5.9"><div class="title"><span class="item-label">Fig. 5.9</span> Nomenclature of skewed distributions. The direction in which the tail points gives the direction of skewing</div><img alt="Figure 49-3" src="XML/9788184484175/Chapters/images/49-3.jpg"><div class="additional-markup"></div></div>
</div>
<div class="section" id="ch5lev3sec7"><h3 class="title">Scatter Plot</h3>
<p>A scatter plot (scattergram) gives a visual impression of the degree and direction of relationship between two variables (<a href="#ch5fig10" class="ulink-inter">Fig. 5.10</a>). Quantification of the relationship is done by calculating the correlation coefficient.<a name="page50"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">50</span></span></p>
<div class="figure" id="ch5fig10" data-label="Fig. 5.10"><div class="title"><span class="item-label">Fig. 5.10</span> A scatter plot showing the relationship between body weight and serum cholesterol level</div><img alt="Figure 50-1" src="XML/9788184484175/Chapters/images/50-1.jpg"><div class="additional-markup"></div></div>
<p>The correlation coefficient should always be accompanied by a scatter plot because the numerical value of the correlation coefficient can be misleading (<a href="#ch5fig11" class="ulink-inter">Fig. 5.11</a>). The correlation coefficient has been discussed in greater detail later.</p>
</div>
<div class="section" id="ch5lev3sec8"><h3 class="title">Line Graph</h3>
<p>Line graphs are commonly used for depicting the change in the value of a variable with time (<a href="#ch5fig12" class="ulink-inter">Fig. 5.12</a>). Time is usually plotted on the X-axis, and the value of the variable on the Y-axis.</p>
</div>
</div>
</div><div class="section" id="ch5lev1sec3"><h1 class="title">CONDENSATION OF DATA</h1>
<p>It was mentioned earlier that presentation of data involves organization and condensation of data. Tables and graphs enable us primarily to organize the data. Now we shall concentrate on techniques for condensing data. As discussed earlier, condensation inevitably involves loss of detail. It is for the investigator to judge how much detail to sacrifice in the interest of clarity and economy of space. The important consideration is that nothing that matters, or is likely to matter, should get concealed in the process of condensation. The most potent tool of condensation is averaging. The arithmetic mean and its cousins are technically called the measures of central tendency. The guilt of condensing lots of values into a single value is partly compensated by giving one or more measurements of dispersion (usually standard deviation and/or range).<a name="page51"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">51</span></span></p>
<div class="figure" id="ch5fig11" data-label="Fig. 5.11"><div class="title"><span class="item-label">Fig. 5.11</span> A correlation coefficient is incomplete without a scatter plot. A correlation coefficient (r) equal to 0.5 may evoke the image of a relationship depicted in ‘A’, but could equally result from the type of relationships shown in ‘B’ and ‘C’. In B, the variables R and S are highly correlated but the r value has been brought down by three outlires. In C, X and Y are not at all correlated; the value of r = 0.5 is the result of two clusters of values (see also <a href="#ch5fig18" class="ulink-inter">Fig. 5.18</a>)</div><img alt="Figure 51-1" src="XML/9788184484175/Chapters/images/51-1.jpg"><div class="additional-markup"></div></div>
<div class="figure" id="ch5fig12" data-label="Fig. 5.12"><div class="title"><span class="item-label">Fig. 5.12</span> Example of a line graph: plasma glucose following oral administration of 75 g glucose after an overnight fast</div><img alt="Figure 51-2" src="XML/9788184484175/Chapters/images/51-2.jpg"><div class="additional-markup"></div></div>
<div class="section" id="ch5lev2sec5"><h2 class="title">Measurements of Central Tendency</h2>
<p>Biological measurements show considerable individual variation, but if we look at the entire range of values, the values near the middle of the range are far more numerous than those at either extreme. In other words, the values have a central tendency. Measures of central tendency give a specific numerical value which reflects this tendency. There are three such measures: mean, median and mode.<a name="page52"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">52</span></span></p>
<div class="section" id="ch5lev3sec9"><h3 class="title">Mean</h3>
<p>Mean, sometimes called the arithmetic mean, or just the ‘average’, is the most commonly used measure of central tendency. It is equal to the sum of individual values divided by the total number of observations.</p>
<p>Mathematically,</p>
<div class="informalfigure"><img alt="Figure 52-1" src="XML/9788184484175/Chapters/images/52-1.jpg"></div>
<p>where <span class="inlinemediaobject"><img alt="Figure xbar" src="XML/9788184484175/Chapters/images/xbar.jpg"></span> is the mean, x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub> … … xn are individual observations, and n is the number of observations.</p>
<p>The mean reflects the central tendency best when the data are normally distributed. One of the drawbacks of the mean is its extreme sensitivity to very low or very high values. For example, the mean income of a poor country may appear respectable simply because of the country also having a few millionaires. Or, the average life expectancy of a population may be brought down drastically by a relatively small number of deaths during infancy.</p>
</div>
<div class="section" id="ch5lev3sec10"><h3 class="title">Median</h3>
<p>To find out the median, all observations are arranged in an ascending order. When the data have been so arranged, the middle value is the median.</p>
<p>If the total number of observations (n) is odd, median = (n+1)/2th value. For example, if n = 17, median is the 9th value. In this case, there will be 8 observations smaller, and 8 observations greater than the median.</p>
<p>If n is even, the median is the mean of the (n/2)th and (n/2+1) th value. For example, if n = 18, the median is the mean of the 9th and 10th value.</p>
<p>The median is more suitable than the mean if the distribution is skewed.</p>
</div>
<div class="section" id="ch5lev3sec11"><h3 class="title">Mode</h3>
<p>In a series of observations, the most frequently occurring value is the mode. Mode is not commonly used, but has a special value if the observations are bimodal (<a href="#ch5fig13" class="ulink-inter">Fig. 5.13</a>). Two modes represent this situation better than either the mean or the median.</p>
<p>In a perfect bell-shaped distribution, the mean, the median and the mode are equal (<a href="#ch5fig14" class="ulink-inter">Fig. 5.14</a>). How they differ from one another when the distribution is skewed has been shown in <a href="#ch5fig15" class="ulink-inter">Figure 5.15A and B</a>.<a name="page53"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">53</span></span></p>
<div class="figure" id="ch5fig13" data-label="Fig. 5.13"><div class="title"><span class="item-label">Fig. 5.13</span> If the distribution is bimodal, two modes (1 and 2) represent the situation much better than either mean or median</div><img alt="Figure 53-1" src="XML/9788184484175/Chapters/images/53-1.jpg"><div class="additional-markup"></div></div>
<div class="figure" id="ch5fig14" data-label="Fig. 5.14"><div class="title"><span class="item-label">Fig. 5.14</span> If the distribution is perfectly ‘normal’ or bell-shaped, the mean, median and mode are equal to ‘x’</div><img alt="Figure 53-2" src="XML/9788184484175/Chapters/images/53-2.jpg"><div class="additional-markup"></div></div>
</div>
</div>
<div class="section" id="ch5lev2sec6"><h2 class="title">Measures of Dispersion</h2>
<p>A measure of central tendency presented without giving any idea of the extent to which individual values are scattered can be misleading. This may be understood by means of an example. A person was told that the depth of a stream had been measured at 10 different points and the average depth was 4 feet.<a name="page54"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">54</span></span></p>
<div class="figure" id="ch5fig15" data-label="Fig. 5.15"><div class="title"><span class="item-label">Fig. 5.15</span> Mean, median and mode when the distribution is skewed positively (A) or negatively (B)</div><img alt="Figure 54-1" src="XML/9788184484175/Chapters/images/54-1.jpg"><div class="additional-markup"></div></div>
<p>He did not know swimming, but since he was more than 5 feet tall, he thought he could cross the stream walking. But somewhere midstream he stepped into an area that was 10 feet deep, and he drowned. The average of 4 feet had been derived from ten values ranging from 1 foot to 10 feet. As seen in <a href="#ch5fig16" class="ulink-inter">Figure 5.16</a>, two widely different types of data may have the same average. In the above example, the person who decided to cross the stream walking visualized a distribution like ‘A’, whereas the actual distribution of data was more like ‘B’ (<a href="#ch5fig16" class="ulink-inter">Fig. 5.16</a>). Indicators which give an idea whether the distribution resembles ‘A’ or ‘B’ are called measures of dispersion, i.e. they assess the degree to which individual values are scattered or dispersed. The two most commonly used measures of dispersion are ‘range’ and ‘standard deviation’.<a name="page55"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">55</span></span></p>
<div class="figure" id="ch5fig16" data-label="Fig. 5.16"><div class="title"><span class="item-label">Fig. 5.16</span> Two widely different distributions, A and B, may have the same mean, median and mode (x). That is why range can give valuable information which the average cannot</div><img alt="Figure 55-1" src="XML/9788184484175/Chapters/images/55-1.jpg"><div class="additional-markup"></div></div>
<div class="section" id="ch5lev3sec12"><h3 class="title">Range</h3>
<p>Strictly speaking, range is the difference between the largest and the smallest observation. But usually the range is expressed by giving both the smallest and the largest value, separating them by a dash. The drawback is that the range considers only the extreme values, which may be far removed from the majority of observations. For example, the monthly income of the majority may range from Rs. 1,000-50,000, but just one millionaire may push the upper end of the range to Rs. 10,000,000.</p>
</div>
<div class="section" id="ch5lev3sec13"><h3 class="title">Standard Deviation</h3>
<p>One may intuitively feel that dispersion may be expressed by finding the average deviation from the mean. Let us see whether this works.</p>
<div class="informaltable"><div class="table-scroll"><table class="download">



<thead>
<tr>
<th class="left"><p><span class="italic">S.No.</span></p></th>
<th class="left"><p><span class="italic">Observation</span></p></th>
<th class="left"><p><span class="italic">Deviation from the mean</span></p></th>
</tr>
</thead>
<tbody>
<tr>
<td class="left"><p>1.</p></td>
<td class="left"><p>30</p></td>
<td class="left"><p>28 – 30 = – 2</p></td>
</tr>
<tr>
<td class="left"><p>2.</p></td>
<td class="left"><p>20</p></td>
<td class="left"><p>28 – 20 = + 8</p></td>
</tr>
<tr>
<td class="left"><p>3.</p></td>
<td class="left"><p>35</p></td>
<td class="left"><p>28 – 35 = – 7</p></td>
</tr>
<tr>
<td class="left"><p>4.</p></td>
<td class="left"><p>25</p></td>
<td class="left"><p>28 – 25 = + 3</p></td>
</tr>
<tr>
<td class="left"><p>5.</p></td>
<td class="left"><p>30</p></td>
<td class="left"><p>28 – 30 = – 2</p></td>
</tr>
<tr>
<td class="left"><p>Sum</p></td>
<td class="left"><p>140</p></td>
<td class="left"><p>Sum of deviations = – 11 + 11 = 0</p></td>
</tr>
<tr>
<td class="left"><p>Mean</p></td>
<td class="left"><p>140/5</p>
<p>= 28</p></td>
<td class="left"><p>Average deviation = 0/5 = 0</p></td>
</tr>
</tbody>
</table></div></div>
<p>It can be proven mathematically that the average deviation will always be zero. Since this idea does not work, we can do one thing: square all the deviations. Since the square of negative as well as positive values is positive, all the squared deviations will be positive. Going back to the previous example.<a name="page56"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">56</span></span></p>
<div class="informaltable"><div class="table-scroll"><table>




<tbody>
<tr>
<td class="left"><p><span class="italic">S.No.</span></p></td>
<td class="left"><p><span class="italic">Observation</span></p></td>
<td class="left"><p><span class="italic">Deviation from the mean</span></p></td>
<td class="left"><p><span class="italic">Square of the deviation</span></p></td>
</tr>
<tr>
<td class="left"><p>1.</p></td>
<td class="left"><p>30</p></td>
<td class="left"><p>− 2</p></td>
<td class="left"><p>4</p></td>
</tr>
<tr>
<td class="left"><p>2.</p></td>
<td class="left"><p>20</p></td>
<td class="left"><p>+ 8</p></td>
<td class="left"><p>64</p></td>
</tr>
<tr>
<td class="left"><p>3.</p></td>
<td class="left"><p>35</p></td>
<td class="left"><p>− 7</p></td>
<td class="left"><p>49</p></td>
</tr>
<tr>
<td class="left"><p>4.</p></td>
<td class="left"><p>25</p></td>
<td class="left"><p>+ 3</p></td>
<td class="left"><p>9</p></td>
</tr>
<tr>
<td class="left"><p>5.</p></td>
<td class="left"><p>30</p></td>
<td class="left"><p>− 2</p></td>
<td class="left"><p>4</p></td>
</tr>
<tr>
<td colspan="4" class="center"><p>Sum of the squares (SS) = 130</p>
<p>Average of squared deviations = 130/5 = 26</p></td>
</tr>
</tbody>
</table></div></div>
<p>The average of squared deviations is called variance. However, this creates another problem: it inflates the dispersion.</p>
<p>Thus in the above example, although individual values do not deviate from the mean by more than 8, the variance is 26. This problem is solved by taking the square root of the variance, which is <bold>called standard deviation</bold> (SD).</p>
<p>Thus SD = the square root of (sum of squared deviations/number of observations).</p>
<p>This is strictly true <span class="italic">only</span> when we are dealing with a whole population, which is rare.</p>
<p>For reasons which are beyond the scope of this book, when dealing with a sample,</p>
<p>SD = the square root of (sum of squared deviations/n–1),</p>
<p>where n is the number of observations.</p>
<p>In the above example,</p>
<p>SD = Square root of 130/(5–1)</p>
<p>= Square root of 130/4</p>
<p>= Square root of 32.5</p>
<p>= 5.7</p>
<p>The summary of our data is usually expressed as mean ± SD. Thus the five observations in the above examples may be summarized as 28 ± 5.7.</p>
<p>The value of this summary may be understood by considering another example.</p>
<div class="informaltable"><div class="table-scroll"><table class="download">




<thead>
<tr>
<th class="left"><p><span class="italic">S.No.</span></p></th>
<th class="left"><p><span class="italic">Observation</span></p></th>
<th class="left"><p><span class="italic">Deviation from the mean</span></p></th>
<th class="left"><p><span class="italic">Square of the deviation</span></p></th>
</tr>
</thead>
<tbody>
<tr>
<td class="left"><p>1.</p></td>
<td class="left"><p>80</p></td>
<td class="left"><p>28 – 80 = −52</p></td>
<td class="left"><p>2704</p></td>
</tr>
<tr>
<td class="left"><p>2.</p></td>
<td class="left"><p>5</p></td>
<td class="left"><p>28 – 5 = 23</p></td>
<td class="left"><p>529</p></td>
</tr>
<tr>
<td class="left"><p>3.</p></td>
<td class="left"><p>15</p></td>
<td class="left"><p>28 – 15 = 13</p></td>
<td class="left"><p>169</p></td>
</tr>
<tr>
<td class="left"><p>4.</p></td>
<td class="left"><p>10</p></td>
<td class="left"><p>28 – 10 = 18</p></td>
<td class="left"><p>324</p></td>
</tr>
<tr>
<td class="left"><p>5.</p></td>
<td class="left"><p>30</p></td>
<td class="left"><p>28 – 30 = −2</p></td>
<td class="left"><p>4</p></td>
</tr>
<tr>
<td class="left"><p>Sum</p></td>
<td class="left"><p>140</p></td>
<td class="left"><p>Sum of squared deviations</p></td>
<td class="left"><p>3730</p></td>
</tr>
<tr>
<td class="left"><p>Mean</p></td>
<td class="left"><p>140/5 = 28</p></td>
<td class="left"></td>
<td class="left"></td>
</tr>
</tbody>
</table></div></div>
<p><a name="page57"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">57</span></span>SD = Square root of 3730/(5-1)</p>
<p>= Square root of 3730/4</p>
<p>= Square root of 932.5</p>
<p>= 30.5</p>
<p>The summary of this data will be 28 ± 30.5. Although the mean in both examples is 28, the wider dispersion in the second example is reflected in the larger SD. The data of these examples may be expressed as follows:</p>
<div class="informaltable"><div class="table-scroll"><table class="download">




<thead>
<tr>
<th class="left"><p><span class="italic">Example</span></p></th>
<th class="left"><p><span class="italic">Mean</span></p></th>
<th class="left"><p><span class="italic">Range</span></p></th>
<th class="left"><p><span class="italic">SD</span></p></th>
</tr>
</thead>
<tbody>
<tr>
<td class="left"><p>1.</p></td>
<td class="left"><p>28</p></td>
<td class="left"><p>20-35</p></td>
<td class="left"><p>5.7</p></td>
</tr>
<tr>
<td class="left"><p>2.</p></td>
<td class="left"><p>28</p></td>
<td class="left"><p>5-80</p></td>
<td class="left"><p>30.5</p></td>
</tr>
</tbody>
</table></div></div>
<p>Reflect on the above Table to grasp the significance of including in the summary, besides the mean, one or more measures of dispersion.</p>
</div>
<div class="section" id="ch5lev3sec14"><h3 class="title">Coefficient of Variation</h3>
<p>The absolute value of the SD depends not only on the degree of scatter around the mean but also on the absolute value of the observations. For example, compare the following sets of observations:</p>
<div class="informaltable"><div class="table-scroll"><table>




<tbody>
<tr>
<td colspan="2" class="center"><p><bold>SET A</bold></p></td>
<td colspan="2" class="center"><p><bold>SET B</bold></p></td>
</tr>
<tr>
<td class="left"><p><span class="italic">S.No.</span></p></td>
<td class="left"><p><span class="italic">Observation</span></p></td>
<td class="left"><p><span class="italic">S. No.</span></p></td>
<td class="left"><p><span class="italic">Observation</span></p></td>
</tr>
<tr>
<td class="left"><p>1.</p></td>
<td class="left"><p>30</p></td>
<td class="left"><p>1.</p></td>
<td class="left"><p>300</p></td>
</tr>
<tr>
<td class="left"><p>2.</p></td>
<td class="left"><p>20</p></td>
<td class="left"><p>2.</p></td>
<td class="left"><p>200</p></td>
</tr>
<tr>
<td class="left"><p>3.</p></td>
<td class="left"><p>35</p></td>
<td class="left"><p>3.</p></td>
<td class="left"><p>350</p></td>
</tr>
<tr>
<td class="left"><p>4.</p></td>
<td class="left"><p>25</p></td>
<td class="left"><p>4.</p></td>
<td class="left"><p>250</p></td>
</tr>
<tr>
<td class="left"><p>5.</p></td>
<td class="left"><p>30</p></td>
<td class="left"><p>5.</p></td>
<td class="left"><p>300</p></td>
</tr>
<tr>
<td class="left"><p>Mean</p></td>
<td class="left"><p>28</p></td>
<td class="left"><p>Mean</p></td>
<td class="left"><p>280</p></td>
</tr>
<tr>
<td class="left"><p>S.D.</p></td>
<td class="left"><p>5.7</p></td>
<td class="left"><p>S.D.</p></td>
<td class="left"><p>57</p></td>
</tr>
</tbody>
</table></div></div>
<p>Although in Set B the SD is 57, the scatter is similar to that in Set A where the SD is only 5.7. Not only is the SD ten times greater in Set B, but each observation is also ten times greater in Set B than in Set A. Thus there is no genuine difference in the scatter. The apparent difference in variability may be neutralized by calculating the coefficient of variation (CV).</p>
<div class="informalfigure"><img alt="Figure 57-1" src="XML/9788184484175/Chapters/images/57-1.jpg"></div>
<p><a name="page58"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">58</span></span>Although, CV is not used much, sometimes it is useful, as in the calculation of intra-assay and inter-assay variation (<a href="/9788184484175/chapter/ch9" class="ulink-exter">Chapter 9</a>).</p>
</div>
</div>
<div class="section" id="ch5lev2sec7"><h2 class="title">Correlation</h2>
<p>If the data suggest that two variables may be related, the relationship may be expressed mathematically through a single value, the correlation coefficient (usually abbreviated as ‘r’). The correlation coefficient gives the degree and direction of the relationship between the two variables. The value of r varies between +1 and −1 (<a href="#ch5fig17" class="ulink-inter">Fig. 5.17</a>). Suppose the value of r for the two variables, x and y, is +1. It means that as the value of x increases, the value of y also increases. If r = 0, it means that there is absolutely no relationship between the values of x and y. If r = −1, it means that as the value of x increases, the value of y decreases. Correlation coefficients of +1 and −1 indicate perfect relationships, and are rare in practice. In the real world, a correlation coefficient of 0.7 is also pretty high. How high is high enough can be assessed by calculation of statistical significance. For this purpose, we first calculate the ‘t’ value.</p>
<div class="figure" id="ch5fig17" data-label="Fig. 5.17"><div class="title"><span class="item-label">Fig. 5.17</span> Three hypothetical correlations. A, as X increases, Y increases perfectly proportionately. B, as X increases, Y decreases perfectly proportionately. C, there is absolutely no relationship between the values of X and Y</div><img alt="Figure 58-1" src="XML/9788184484175/Chapters/images/58-1.jpg"><div class="additional-markup"></div></div>
<div class="informalfigure"><img alt="Figure 58-2" src="XML/9788184484175/Chapters/images/58-2.jpg"></div>
<p>If we know the ‘t’ value, the P value may be read out from a standard Table. A P value of less than 0.05 is usually considered significant. We shall return to P values in greater detail in a subsequent section.</p>
<p>The correlation coefficient generally calculated is Pearson's correlation coefficient. Pearson's coefficient is valid only when the variables are normally distributed. Further, Pearson's coefficient is <a name="page59"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">59</span></span>markedly affected by extreme values (called outliers). If the distribution is skewed, or outliers are present, Spearman's rank correlation coefficient is more appropriate.</p>
<p>A correlation coefficient should always be accompanied by a two-way scatter plot because the numerical value can be misleading. The same numerical value may represent a variety of relationships (<a href="#ch5fig11" class="ulink-inter">Figs 5.11</a> and <a href="#ch5fig18" class="ulink-inter">5.18</a>). Another important principle brought out by <a href="#ch5fig18" class="ulink-inter">Figure 5.18</a> is that it is appropriate to calculate the correlation coefficient only when the relationship between variables is linear. A non-linear relationship (<a href="#ch5fig18" class="ulink-inter">Fig. 5.18A to C</a>) should be represented only by a scatter plot.</p>
<div class="section" id="ch5lev3sec15"><h3 class="title">Coefficient of Determination</h3>
<p>The square of the correlation coefficient is called the coefficient of determination (usually abbreviated as r<sup>2</sup>). Although it is beyond the scope of this book to explain why it is so, r<sup>2</sup> gives the extent to which the variation in one of the two variables involved may be explained by the variation in the other. For example, suppose the correlation coefficient of the relationship between intelligence quotient (IQ) and performance in the examination is 0.7. If r = 0.7, r<sup>2</sup> = 0.49. Hence only 49% of variation in performance is explained by the variation in IQ. The remaining 51% of variation in performance is due to other factors such as hard work, learning style, aptitude and ‘luck’. The important point to grasp is that even when the value of r is quite high like 0.7, r<sup>2</sup> is much smaller. Hence r should be interpreted with caution because the relationship between the two variables gives only part of the story.</p>
</div>
<div class="section" id="ch5lev3sec16"><h3 class="title">Uses of Correlation Coefficient</h3>
<p>Suppose a high correlation is observed between a biochemical or genetic marker and the occurrence of a disease such as diabetes or breast cancer later in life.</p>
<div class="figure" id="ch5fig18" data-label="Fig. 5.18"><div class="title"><span class="item-label">Fig. 5.18</span> A correlation coefficient is incomplete without a scatter plot. A correlation coefficient (r) equal to 0.0 may evoke the image of a relationship depicted in ‘A’, but could equally result from the type of relationships shown in ‘B’ and ‘C’ (see also <a href="#ch5fig11" class="ulink-inter">Figure 5.11</a>)</div><img alt="Figure 59-1" src="XML/9788184484175/Chapters/images/59-1.jpg"><div class="additional-markup"></div></div>
<a name="page60"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">60</span></span>
<div class="figure" id="ch5fig19" data-label="Fig. 5.19"><div class="title"><span class="item-label">Fig. 5.19</span> Marks obtained in OSPE (A) and the conventional exam (EXPT) (B) in the December 1982 and March 1983 exams. A, n = 49, r = 0.81; B, n = 49, r = 0.40. <span class="italic">(Reproduced from Nayar U, Malik SL, Bijlani RL. Med Edu 1986; 20: 204-209)</span></div><img alt="Figure 60-1" src="XML/9788184484175/Chapters/images/60-1.jpg"><div class="additional-markup"></div></div>
<p>The value of the correlation coefficient tells us the confidence with which the disease may be predicted in a person in later life, and the early precautions that may be justified. For further accuracy, a regression equation may be calculated, which gives us the likely value of variable y if the value of variable x is known.</p>
<p>Correlation coefficient may also be used for assessing test-retest reliability and inter-observer reliability of a test, be it an instrument of examination or a biochemical test. For example, in the early days of objective structured practical examination (OSPE), its test-retest reliability was compared with that of the traditional examination in which the student did a full experiment in the exam (<a href="#ch5fig19" class="ulink-inter">Fig. 5.19</a>). The much higher test-retest reliability helped establish OSPE as a better instrument of assessment. The other aspect of reliability is the inter-observer reliability, i.e. for the same performance (or same blood sample) how much difference does changing the examiner (or technician) make to the score (or the value reported). For a multiple choice question (MCQ) test, the correlation between scores given by two examiners is perfect (r = 1.0). It is less for short structured questions, and the least for long essay questions.</p>
</div>
<div class="section" id="ch5lev3sec17"><h3 class="title">Limitations of Correlation Coefficient</h3>
<p>Some limitations, such as its suitability only for linear relationships, have already been referred to. One more important limitation which needs to be understood is that the correlation coefficient only gives <a name="page61"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">61</span></span>us the strength of association between two variables, not the nature of the relationship. A high correlation coefficient does not prove a cause-effect relationship. For example, a high correlation between watching TV and obesity does not prove that watching TV, by itself, leads to obesity: the association is casual, not causal. The correlation between sedentary habits and watching TV is also high, but again it does not prove whether sedentary habits lead to watching too much TV, or whether watching too much TV makes a person sedentary: to some extent both may be true. In fact, a third variable, viz. not having much of interesting work to do may promote both sedentary habits and watching TV, thereby creating the high correlation between sedentariness and TV watching.</p>
<div class="sidebar">
<h2 class="title">Where lies statistics</h2>
<p>The term “statistics” (<span class="italic">statistica,</span> statesman) was coined by Gottfried Achenwall in 1752 to describe the type of knowledge required to govern a country, roughly the equivalent of present day political science. The relationship between this first use of the term and its contemporary use may be understood from the fact that in the 18th century Europe it began to be realized that accurate knowledge about population – its size, birth and death rates, causes of death, etc. – was important for the government. The 18th century term for collection of demographic data was “political arithmetic”. The description of demography as political arithmetic lasted almost the entire 18th century. It was in 1798 that John Sinclair used the term “statistics” to describe the data and methods of political arithmetic. From then on “statistics” gradually came to denote less and less of politics, and more and more of mathematics. Since mathematics is a science, in 1830 a proposal was made to form a Statistics Section of the British Association for the Advancement of Science. Before taking the decision on the proposal a subcommittee was formed under the leadership of Thomas Malthus to answer the question “Is statistics a branch of science?” The conclusion of the subcommittee was interesting: it agreed that collection and tabulation of data was science, but there was violent disagreement on whether statistical interpretation of data was respectable enough to be considered a science. The anti-inference group triumphed, and the victory was repeated in 1834 when the Statistical Society of London (later renamed Royal Statistical Society) was formed. The determination to keep interpretation out of science was reflected in the motto of the society, <span class="italic">Aliis exterendum,</span> which means “Let others thrash it out”. “Others” here has an undercurrent of contempt towards those who interpret results. They were considered not dignified enough to join the club of scientists because they consisted of politicians and their academic accomplices who were not necessarily interested in seeing the truth: they would much rather make truth look politically correct. Although keeping inferential statistics out of science was like throwing the baby with the bathwater, and the exclusion did not last very long, the historical mistrust of statistical conclusions is reflected even today in the hackneyed expression, ‘a statistical lie’, which is considered worse than just ‘a lie’ or even ‘a white lie’!</p>
</div>
</div>
</div>
</div><div class="section" id="ch5lev1sec4"><h1 class="title">INFERENTIAL STATISTICS</h1>
<p>What we have discussed in this chapter so far are the tools for organizing the data and for making massive amounts of data manageable by representing the essence of the data through a few figures such as mean and SD, and sometimes r. All these techniques <a name="page62"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">62</span></span>are included in the blanket term, <bold>descriptive statistics.</bold> Wherever unavoidable, we have also touched on the inferences that may, or may not be drawn from the organized and condensed data. Now we shall discuss the statistical tools available for dispassionate and objective interpretation of data. These tools are broadly termed inferential statistics. Before going into the tools of <bold>inferential statistics,</bold> it would be worthwhile to understand two commonly used terms: probability and confidence interval.</p>
<p><bold>Probability</bold> is the degree of likelihood of an event occurring. Mathematically, probability varies from 0 to 1. A probability of 0 means that it is certain that the event <span class="italic">will not</span> occur. A probability of 1 means that it is certain that the event <span class="italic">will</span> occur. If a coin is tossed repeatedly a sufficient number of times, in all likelihood we will get heads half of the times, and tails the other half of the times. Hence probability of getting a head is 0.5. The probability of getting a tail is also 0.5, or 50%.</p>
<p><bold>Confidence interval</bold> is a range of values which include the true value with a high probability (usually greater than 95% probability). Let us take an example to understand the concept. Suppose you are shown a fat person and asked his weight. You make a guess, 100 kg. Then you are asked how sure you are. You say, well, it is between 90 and 110 kg. You are again asked if you are very sure. You say, O.K., it is definitely between 80 and 120 kg. The range 90-110 kg, or 80-120 kg, is a confidence interval. As the confidence interval widens, the confidence increases that it includes the true value.</p>
<p>Let us take a look at the confidence interval another way. In research we collect data from a sample, which we try to make as representative of the population as possible. We condense the data into a mean and SD. How confident are we that these values are truly representative of the population? For example, what is the probability that the sample mean is the true population mean? Assuming an ideal sampling procedure, larger the sample size, higher is the probability (p) that the sample mean is the true population mean. Conversely, we can fix the desired p level, say, at 0.95. For a p value of 0.95, the true population mean is included in the range, the observed mean ± y. The larger the sample size, for a given p value, the smaller will be the value of y, or the narrower will be the range called the confidence interval. Thus larger the sample size, narrower is the confidence interval. For example, suppose the mean weight of 10-year old boys in a study done in the city of Delhi is 40 kg.<a name="page63"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">63</span></span></p>
<div class="figure" id="ch5fig20" data-label="Fig. 5.20"><div class="title"><span class="item-label">Fig. 5.20</span> In normally distributed data, Mean ± SD typically includes 67% of the population, and Mean ± SD 95 percent. That leaves 5% of the population with extreme values, 2.5% below Mean – 2 SD, and 2.5% above Mean + 2 SD</div><img alt="Figure 63-1" src="XML/9788184484175/Chapters/images/63-1.jpg"><div class="additional-markup"></div></div>
<div class="sidebar">
<h2 class="title">Confidentially yours…..</h2>
<p>Higher the confidence level (or p value) desired, wider the confidence interval.</p>
<p>Larger the sample size, narrower the confidence interval.</p>
</div>
<p>If the sample size is only 20 boys, we might say with 95% confidence that the true mean weight of the entire population of 10-year old boys in the city of Delhi is 40 ± 5 kg, i.e. 35-45 kg (95% confidence means p = 0.95). If the sample size is 1000 boys, we might be able to say with 95% confidence that the true mean weight of 10-year old boys in Delhi is 40 ± 1 kg, i.e. 39-41 kg<sup><a href="#ch5fn1" class="ulink-inter">1</a></sup>. Thus the larger sample size has narrowed down the confidence interval. However, if we wish to increase the confidence to 99% (p = 0.99), we might have to widen the confidence interval to 38-42 kg even with a sample size of 1000.</p>
<p>Another related concept is the extent to which mean and SD together represent the population. For an adequately large sample size (usually, 30 or more), for normally distributed unimodal data, mean ± SD includes 67% of the population, and mean ± 2SD includes 95% of the population (<a href="#ch5fig20" class="ulink-inter">Fig. 5.20</a>).</p>
<div class="section" id="ch5lev2sec8"><h2 class="title">Hypothesis Testing</h2>
<p>Most experimental studies start with a hypothesis, and the purpose of the study is to determine whether the hypothesis is true (<a href="#ch5fig21" class="ulink-inter">Fig. 5.21</a>). The hypothesis is usually based on previous literature, or a hunch.</p>
<p>_______________________</p>
<p><sup class="footnote" id="ch5fn1">[<a href="#d1e4050">11</a>]</sup></p>
<a name="page64"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">64</span></span>
<div class="figure" id="ch5fig21" data-label="Fig. 5.21"><div class="title"><span class="item-label">Fig. 5.21</span> My hypothesis that sleep is not a necessity stands proved. This subject can walk even after 10 days of sleep deprivation! <span class="italic">(Idea: Dr Arvind Kairo, AIIMS)</span></div><img alt="Figure 64-1" src="XML/9788184484175/Chapters/images/64-1.jpg"><div class="additional-markup"></div></div>
<p><a name="page65"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">65</span></span>Since the hypothesis is about a population, whereas the study is done on a sample, no study can actually prove whether the hypothesis is true. The classical technique of hypothesis testing consists of the round about way of examining how low is the probability that the hypothesis is false. How low a probability would be acceptable is decided before the study is begun: conventionally, it is fixed at less than 5 percent. Let us study the process of hypothesis testing with the help of an example.</p>
<p>Suppose the study has been done to examine the efficacy of treatment ‘A’ through a randomized placebo-controlled trial. Although we expect the treatment to be effective, we examine the hypothesis, ‘the treatment is not effective’. This is called the null hypothesis (H<sub>0</sub>). Since the hypothesis with which the study was begun was different, viz. ‘the treatment is effective’, we call this hypothesis the alternative hypothesis (H<sub>A</sub>), because it is an alternative to the null hypothesis. We analyse the data for the difference between the outcome in the placebo group and the treatment group. Suppose the data are in the direction expected according to H<sub>A</sub>. Then we apply appropriate statistical tests to determine the significance of the difference between the outcomes in the two groups. These tests examine the null hypothesis, and give us the probability (p value) of the null hypothesis being true. If the p value is less than 0.05, it means that there is less than 5% probability of the null hypothesis being true. In other words, there is less than 5% probability that the treatment is not effective. Stated another way, the probability of the treatment being effective is more than 95%.</p>
<p>Moving away from the above example, in general when p &lt; 0.05, it implies that there is less than 5% probability that the observed trend or pattern is due to chance or accidental factors. It indirectly implies that there is a greater than 95% probability that the observed trend or pattern is genuine, and hence the results of the study can be extrapolated from the sample to the population in which we are interested.</p>
<p>In short, we start the analysis on the basis of the null hypothesis. If we find the probability of the null hypothesis being true is extremely low, we reject it. Rejecting the null hypothesis means that we accept the alternative hypothesis as probably true. This is what is meant by the statement that scientific proof is based on falsification. The technique is to examine if the null hypothesis can be falsified. The method is based on the premise that science cannot prove with absolute certainty anything to be absolutely true.<a name="page66"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">66</span></span></p>
<div class="section" id="ch5lev3sec18"><h3 class="title">Type I and Type II Errors</h3>
<p>The fact that scientific studies never arrive at conclusions with absolute certainty means that there is always a probability of making an error. The potential errors are classified into type I and type II.</p>
<p>Type I error leads to unwarranted jubilation. We mistakenly conclude that our hypothesis has been supported by the study, whereas actually the hypothesis is not true. Type I error can be avoided by fixing a lower level of probability for rejecting the null hypothesis (this level is called alpha). For instance, if we consider p &lt; 0.05 to be significant, we may make a type I error. But if we consider p &lt; 0.01 to be significant, there is less probability of making a type I error.</p>
<p>Type II error is the result of unduly excessive caution. We mistakenly conclude that our hypothesis has not been supported by the study, whereas actually the hypothesis is true. Type II error can be avoided by not fixing alpha at too low a level. That is why alpha is usually fixed at 0.05, and seldom below 0.01. The probability of type II error is called ‘beta’.</p>
<p>From the above discussion it may seem that the choice is between the fire and the frying pan. To some extent it is true that avoiding one type of error increases the probability of the other type of error. One factor which can reduce both types of error is a larger sample size. A sufficiently large and truly representative sample is the best guarantee that the results obtained on the sample truly reflect the results that would be obtained if the whole population were to be studied.</p>
</div>
<div class="section" id="ch5lev3sec19"><h3 class="title">Power</h3>
<p>Power is the attribute of a study. The power of a study is the probability of its correctly validating the hypothesis, if the hypothesis is true. For example, if the power of a study is 0.9, it means that there is a 90% chance that a hypothesized effect will be identified by the study if the effect exists. The power is equal to (1 – beta), and is not simply the inverse of alpha, as might be intuitively guessed. The power desired in a study is vital for calculation of minimum sample size. Calculation of beta, power, and sample size are beyond the scope of this book, but as might be expected, the larger the sample size, the greater is the power. The task can be much simplified by using an online power calculator, some of which are available free of charge.</p>
<p>Thus, a larger sample size improves the power of a study, and reduces both types of error. But studying a large sample needs more time, more subjects or animals, and often also more personnel and money for consumables. Since all these are often not available, an <a name="page67"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">67</span></span>agonizingly large number of studies end on the note, “… the conclusions drawn from the study are tentative because of the small sample size. Another study on a larger number of subjects is needed for reaching definitive conclusions”. The other “needed” study invariably stays at the level of a noble intention, and an imposing edifice is built up on a large number of ‘pilot studies’ with ‘tentative conclusions’.</p>
</div>
</div>
<div class="section" id="ch5lev2sec9"><h2 class="title">Selection of Statistical Tests</h2>
<p>The purpose of a statistical test is to assess the probability with which the study has thrown up a sample, the result of which can be extrapolated to the population. For this to be done reliably, the sample should be large, the variance small, and the effect large. All these things may not be realizable in practice. The variance may depend on the variable (e.g. serum triglyceride levels have a much larger variance than serum cholesterol). The effect may not be large but that does not mean it is not relevant: a small effect may be clinically important. Therefore what we can really do is simply to have adequate sample size, and to take reasonable care to have a representative sample.</p>
<p>While no amount of sophisticated and complicated statistics can compensate for the faults in design or execution of a study, it is good to keep in mind that different situations call for a different statistical test. The first point to consider is whether we are interested in evaluating differences between groups, or differences between proportions.</p>
<div class="section" id="ch5lev3sec20"><h3 class="title">Differences Between Groups</h3>
<p>The next point to consider is whether we are dealing with two or more than two groups. For more than two groups, the analysis of variance (ANOVA) should precede any test of significance. ANOVA only tells us whether at least one group is different from some other groups. If that is so, we apply tests to evaluate the differences between the pairs of groups which have scientific relevance. Another consideration, irrespective of the number of groups, is whether the data are normally distributed. If the distribution is not normal, non-parametric tests are necessary. Non-parametric tests depend on the median, not the mean. In these tests the null hypothesis states that the medians of the two groups are equal. Yet another consideration is the fact whether observations have been made on the subject at different points in time, e.g. before treatment and after treatment (paired observations or dependent samples); or observations have <a name="page68"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">68</span></span>been made on different groups of subjects, e.g. drug-treated subjects and placebo-treated subjects (unpaired observations or independent samples).</p>
</div>
<div class="section" id="ch5lev3sec21"><h3 class="title">Differences Between Proportions</h3>
<p>In some situations, comparing proportions is the most sensible thing to do. For example, in two alternative treatments for cancer, it may be appropriate to simply compare the proportion of patients who are alive after 5 years in the two groups.</p>
</div>
<div class="section" id="ch5lev3sec22"><h3 class="title">The Last Word?</h3>
<p>The tests recommended in different situations have been summarized in <a href="#ch5fig22" class="ulink-inter">Figure 5.22</a>. But choice based on the figure cannot be considered the last word. It is always advisable to consult a statistician at every stage, including analysis of results.</p>
<p>The formulae for applying these tests are beyond the scope of this book, and are in any case rarely used these days because several excellent software packages (such as SPSS) are available. However, a feel of the data and tests applied is still important. Further, with analysis having become easy with computers, there is a tendency to over-analyse. Instead of making comparisons every-which-way, it is better to restrict to comparisons which are scientifically important. The pull of p &lt; 0.05 is so seductive that sometimes students let the analysis run horizontally, vertically and diagonally, collect meters of printouts, and then start searching where all p is less than 0.05. At some places p &lt; 0.05 may be scientifically meaningless (e.g. if the value of a variable in one group is 0, even a value as low as 0.1 will be significantly different from it, but may not mean much). It is ultimately the scientist who has to decide which comparisons are of interest, and what magnitude of effect is scientifically relevant. Software is a good servant, but cannot play the role of the master.</p>
</div>
</div>
</div><div class="section" id="ch5lev1sec5"><h1 class="title">INTERPRETATION</h1>
<p>“Milk the data dry” was the pet expression of my mentor at MIT, Prof. Nevin Scrimshaw, with which he used to nudge the students to examine and analyse the data from all possible angles. After the data has been milked dry, the next step is to draw conclusions. The interpretation of results needs, besides analysis, scientific judgment. The judgment is guided by analysis, but analysis is not a substitute for judgment. Judgment needs a scientific knowledge of the subject, some prediction about the likely clinical implications of the research, <a name="page69"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">69</span></span>and some intangible and undefinable factors usually wrapped up in expressions such as experience, wisdom and intuition. Statistical significance is not, by itself, proof of the scientific or clinical significance of the results. On the other hand, inability to reject the null hypothesis on statistical grounds does not necessarily mean that the hypothesis with which the study began is not true. Other alternative explanations for negative results could be: an inadequate sample size, a biased sample, or very high random variability in the outcome variable.</p>
<div class="figure" id="ch5fig22" data-label="Fig. 5.22"><div class="title"><span class="item-label">Fig. 5.22</span> Choosing the right statistical test</div><img alt="Figure 69-1" src="XML/9788184484175/Chapters/images/69-1.jpg"><div class="additional-markup"></div></div>
<p><a name="page70"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">70</span></span>Another issue which crops up after analysis of results is that several hypotheses, which the investigators did not have in mind when they started the study, now seem plausible. Valuable though these leads are, the study should not be considered to have provided evidence for the new hypotheses. These should be considered mere trends which need to be examined through another study specifically designed for the purpose. That is how a study may or may not answer satisfactorily the question it was originally designed to answer, but it may supply new questions for future studies. Hence the expression, a study raises more questions than it answers. Thus, research becomes an ever-expanding, endless enterprise. Once a few good studies have been done, there is never a scarcity of ideas for further research: the problem is, which of the ideas to pursue further. Any scientist who does not have more ideas than the time and resources needed to pursue them is not in the right business.</p>
<p><bold>QUESTIONS AND PROBLEMS</bold></p>
<ol style="list-style-type: decimal">
<li><p>What is wrong with the bar charts in <a href="#ch5fig23" class="ulink-inter">Figure 5.23</a>?</p></li>
<li><p>Why is ANOVA done prior to paired comparisons if we are dealing with three or more groups?</p></li>
<li><p>If non-parametric tests do not necessarily require data to have a normal distribution, would it not be better to always use non-parametric tests?</p></li>
</ol>
<p><bold>ANSWERS AND SOLUTIONS</bold></p>
<ol style="list-style-type: decimal">
<li><p>Let us take the two graphs, based on the same data, one by one.</p>
<p>The <span class="italic">upper graph</span> is difficult to read because the natural tendency is to compare adjacent bars. Therefore, while drawing the graph it is best to place those bars next to each other which it is important to compare. In this case it is more important to compare total cholesterol at 0 wk and 4 wk than to compare total cholesterol and LDL cholesterol at 0 wk. Therefore the lower graph is much easier to read. But in the <span class="italic">lower graph,</span> the scale on the Y-axis begins with 100 mg/dL. This is, strictly speaking, not wrong because we do not have any value below 100 mg/dL. But such a graph is misleading because it accentuates the change in cholesterol level which has occurred over 4 wk. Both these drawbacks have been taken care of in <a href="#ch5fig24" class="ulink-inter">Figure 5.24</a>.</p></li>
<li><p>There are two reasons for this, one related to convenience and another to validity.</p>
<ol style="list-style-type: lower-alpha">
<li><p>If there are ten groups to compare, there are 45 pairs which may possibly be compared. This will be very cumbersome.<a name="page71"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">71</span></span></p>
<p><div class="figure" id="ch5fig23" data-label="Fig. 5.23"><div class="title"><span class="item-label">Fig. 5.23</span> Serum total cholesterol and LDL cholesterol at the beginning (0 wk) and end (4 wk) of an intervention</div><img alt="Figure 71-1" src="XML/9788184484175/Chapters/images/71-1.jpg"><div class="additional-markup"></div></div></p></li>
<li><p>Doing ANOVA first makes testing more conservative. It may be possible to compare two groups: one with the highest, and the other with the lowest mean value, and demonstrate significance. But this comparison will not get done at all if ANOVA shows no significant difference between any of the groups. Hence doing paired comparison without ANOVA increases the chances of type I error in case of three or more groups.</p></li>
</ol></li>
<li><p>Although non-parametric tests are distribution free, using them universally is not appropriate because:<a name="page72"></a><span class="pageBreak"></span><span class="pageNumbers"><span class="bottomPage">72</span></span></p>
<p><div class="figure" id="ch5fig24" data-label="Fig. 5.24"><div class="title"><span class="item-label">Fig. 5.24</span> Serum total cholesterol and LDL cholesterol at the beginning (0 wk) and end (4 wk) of an intervention</div><img alt="Figure 72-1" src="XML/9788184484175/Chapters/images/72-1.jpg"><div class="additional-markup"></div></div></p>
<ol style="list-style-type: lower-alpha">
<li><p>they do not use all the information available (because they depend on the median), and</p></li>
<li><p>the power of the study is reduced, i.e. there is a greater chance of type II error.</p></li>
</ol></li>
</ol>
<div class="bibliography" id="ch5bib">
<h2 class="title">Reference</h2>
<li class="row" id="ch5bib1"><div class="ref-content cell"><a href="#">1.</a> Moye LA. Statistical Reasoning in Medicine: the intuitive p-value primer. New York: Springer-Verlag, 2000: 6-10.</div></li>
</div>
</div></div></div>